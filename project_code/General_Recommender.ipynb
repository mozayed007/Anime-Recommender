{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e07a14e7",
      "metadata": {
        "id": "e07a14e7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **1-Dataset Analysis:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d67f80f",
      "metadata": {
        "id": "3d67f80f",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## *i) Cleaning Dataset:* <br />\n",
        "   Jan 23 Last edits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc326491",
      "metadata": {
        "id": "bc326491"
      },
      "source": [
        "Latest check 30th of Jan. 2023 at 5:00PM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3dcbc79",
      "metadata": {
        "id": "e3dcbc79",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **Importings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b1879af-3046-4b04-ba44-5921bd475314",
      "metadata": {
        "id": "8b1879af-3046-4b04-ba44-5921bd475314",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.express as px\n",
        "from ast import literal_eval\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aa08999a",
      "metadata": {
        "id": "aa08999a",
        "outputId": "95aafdc4-e06b-4dd4-b2f2-8342e14cdc59",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23936, 31)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>media_type</th>\n",
              "      <th>mean</th>\n",
              "      <th>num_scoring_users</th>\n",
              "      <th>status</th>\n",
              "      <th>num_episodes</th>\n",
              "      <th>start_date</th>\n",
              "      <th>end_date</th>\n",
              "      <th>source</th>\n",
              "      <th>...</th>\n",
              "      <th>studios</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>nsfw</th>\n",
              "      <th>created_at</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>main_picture_medium</th>\n",
              "      <th>main_picture_large</th>\n",
              "      <th>alternative_titles_en</th>\n",
              "      <th>alternative_titles_ja</th>\n",
              "      <th>alternative_titles_synonyms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16498</td>\n",
              "      <td>Shingeki no Kyojin</td>\n",
              "      <td>tv</td>\n",
              "      <td>8.53</td>\n",
              "      <td>2585993</td>\n",
              "      <td>finished_airing</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2013-04-07</td>\n",
              "      <td>2013-09-29</td>\n",
              "      <td>manga</td>\n",
              "      <td>...</td>\n",
              "      <td>['Wit Studio']</td>\n",
              "      <td>Centuries ago, mankind was slaughtered to near...</td>\n",
              "      <td>white</td>\n",
              "      <td>2012-12-05 12:03:21</td>\n",
              "      <td>2023-01-12 15:12:07</td>\n",
              "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
              "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
              "      <td>Attack on Titan</td>\n",
              "      <td>進撃の巨人</td>\n",
              "      <td>['AoT', 'SnK']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id               title media_type  mean  num_scoring_users  \\\n",
              "0  16498  Shingeki no Kyojin         tv  8.53            2585993   \n",
              "\n",
              "            status  num_episodes  start_date    end_date source  ...  \\\n",
              "0  finished_airing          25.0  2013-04-07  2013-09-29  manga  ...   \n",
              "\n",
              "          studios                                           synopsis   nsfw  \\\n",
              "0  ['Wit Studio']  Centuries ago, mankind was slaughtered to near...  white   \n",
              "\n",
              "            created_at           updated_at  \\\n",
              "0  2012-12-05 12:03:21  2023-01-12 15:12:07   \n",
              "\n",
              "                                 main_picture_medium  \\\n",
              "0  https://api-cdn.myanimelist.net/images/anime/1...   \n",
              "\n",
              "                                  main_picture_large alternative_titles_en  \\\n",
              "0  https://api-cdn.myanimelist.net/images/anime/1...       Attack on Titan   \n",
              "\n",
              "  alternative_titles_ja alternative_titles_synonyms  \n",
              "0                 進撃の巨人              ['AoT', 'SnK']  \n",
              "\n",
              "[1 rows x 31 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= pd.read_csv(\"../data-history/up-to-date-MAL/anime_Feb23.csv\")\n",
        "\n",
        "\n",
        "print(data.shape)\n",
        "data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a17cace5",
      "metadata": {
        "id": "a17cace5",
        "outputId": "22e97d4d-74a7-4f81-a869-591f8a93f4b9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season',\n",
              "       'broadcast_day_of_the_week', 'broadcast_start_time', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at',\n",
              "       'main_picture_medium', 'main_picture_large', 'alternative_titles_en',\n",
              "       'alternative_titles_ja', 'alternative_titles_synonyms'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65024cbe",
      "metadata": {
        "id": "65024cbe",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Taking care of nulls and drops:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e9875ecd",
      "metadata": {
        "id": "e9875ecd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "drops=[\"main_picture_medium\",\"main_picture_large\",\"broadcast_day_of_the_week\",\"broadcast_start_time\",\"alternative_titles_en\",\"alternative_titles_ja\",\"alternative_titles_synonyms\"]\n",
        "data_main=data.drop(drops,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8134a3f6",
      "metadata": {
        "id": "8134a3f6",
        "outputId": "9699a8e7-11ff-4610-d112-04874aec5cd9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43697"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(data_main.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c4d0b3e6",
      "metadata": {
        "id": "c4d0b3e6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.fillna(value=data['mean'].mean,inplace=True)\n",
        "data_main.fillna(value=data['rank'].mean,inplace=True)\n",
        "data_main.fillna(value=data['num_favorites'].mean,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "061316ef",
      "metadata": {
        "id": "061316ef",
        "outputId": "1a48fc32-9820-4c80-bcf1-d01b928fa261"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(data_main.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c24d67d4",
      "metadata": {
        "id": "c24d67d4",
        "outputId": "8ae288ba-4fc3-4424-ec59-e57ed2488a14",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(23936, 24)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_main.dropna(subset=['mean','source','num_episodes','start_date','end_date','rank','average_episode_duration','rating','start_season_year','synopsis'],inplace=True)\n",
        "print(sum(data_main.isnull().sum()))\n",
        "print(data_main.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "df0a376e",
      "metadata": {
        "id": "df0a376e",
        "outputId": "4e57dba3-68be-400d-f86b-a7dcf8d354a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                          23936\n",
              "title                       23936\n",
              "media_type                      7\n",
              "mean                          556\n",
              "num_scoring_users            8214\n",
              "status                          3\n",
              "num_episodes                  252\n",
              "start_date                   8224\n",
              "end_date                     8035\n",
              "source                         17\n",
              "num_list_users              10784\n",
              "popularity                  23767\n",
              "num_favorites                1768\n",
              "rank                        21633\n",
              "average_episode_duration     2917\n",
              "rating                          7\n",
              "start_season_year             102\n",
              "start_season_season             5\n",
              "genres                       5282\n",
              "studios                      1488\n",
              "synopsis                    19294\n",
              "nsfw                            2\n",
              "created_at                  23936\n",
              "updated_at                  23903\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0af7069e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b047a3d",
      "metadata": {
        "id": "7b047a3d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Encoding and Adjusting Dtypes:\n",
        " Using separate Data_Frame for reviewing, Yes, Enough ram is available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaeb556",
      "metadata": {
        "id": "feaeb556"
      },
      "source": [
        "###  NLP Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d20d476",
      "metadata": {
        "id": "9d20d476",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### **Applying Key-BERT for Keywords extraction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c33b9a21",
      "metadata": {
        "id": "c33b9a21",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tqdm.notebook import tqdm\n",
        "import ast\n",
        "import re\n",
        "import spacy as sp\n",
        "from keybert import KeyBERT\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ccf05961",
      "metadata": {
        "id": "ccf05961",
        "outputId": "29d4eee1-a44a-49f6-e368-5015ef204cf9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                  Shingeki no Kyojin\n",
              "1                          Death Note\n",
              "2    Fullmetal Alchemist: Brotherhood\n",
              "3                       One Punch Man\n",
              "4                    Sword Art Online\n",
              "5               Boku no Hero Academia\n",
              "6                    Kimetsu no Yaiba\n",
              "7                              Naruto\n",
              "8                         Tokyo Ghoul\n",
              "9              Hunter x Hunter (2011)\n",
              "Name: title, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.title.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a7aa8b92",
      "metadata": {
        "id": "a7aa8b92",
        "outputId": "31b70f93-a7fd-4b94-dd7c-c6bc46b9522b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "brutal murders petty thefts and senseless violence pollute the human world in contrast the realm of death gods is a humdrum unchanging gambling den the ingenious year old japanese student light yagami and sadistic god of death ryuk share one belief their worlds are rotten for his own amusement ryuk drops his death note into the human world light stumbles upon it deeming the first of its rules ridiculous the human whose name is written in this note shall die however the temptation is too great and light experiments by writing a felon s name which disturbingly enacts his first murder aware of the terrifying godlike power that has fallen into his hands light under the alias kira follows his wicked sense of justice with the ultimate goal of cleansing the world of all evil doers the meticulous mastermind detective l is already on his trail but as light s brilliance rivals l s the grand chase for kira turns into an intense battle of wits that can only end when one of them is dead\n"
          ]
        }
      ],
      "source": [
        "NLP = sp.load(\"en_core_web_lg\")\n",
        "TITLE = 'Death Note'\n",
        "key_model = KeyBERT()\n",
        "data_main = data_main[~data_main.title.duplicated(keep='first')]\n",
        "text = data_main[data_main['title'] == TITLE].synopsis.values[0]\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "    text = text.replace('\\n', \"\").replace('\\r', \"\")\n",
        "    text = text.replace('', \"\")\n",
        "    text = re.sub('[^a-zA-Z]', \" \", str(text))\n",
        "    text = ' '.join(text.split())\n",
        "    text = text.lower()\n",
        "    doc = NLP(text)\n",
        "    return doc\n",
        "\n",
        "doc = clean_text(text)\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "75a792fe",
      "metadata": {
        "id": "75a792fe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.loc[:,'cleaned_syn'] = data_main.loc[:,'synopsis'].astype(str).apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "40453053",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at',\n",
              "       'cleaned_syn'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "da40e5b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_string=data_main[['title','synopsis','cleaned_syn']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a86ce1d7",
      "metadata": {
        "id": "a86ce1d7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df_num=pd.get_dummies(data_main, columns=[\"media_type\",\"source\",\"nsfw\",\"genres\",\"rating\",\"studios\"], prefix=[\"media_type\",\"source\",\"nsfw\",\"genres\",\"rating\",\"studios\"])\n",
        "df_num[['title','mean','num_scoring_users','num_episodes','popularity','rank']]=data_main[['title','mean','num_scoring_users','num_episodes','popularity','rank']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7236910f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((23936, 6822), (23936, 3))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_num.shape,df_string.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb998201",
      "metadata": {
        "id": "bb998201",
        "outputId": "3382e06a-26d9-4658-814f-77ac25325425",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Based on https://stackoverflow.com/questions/48925328/how-to-get-all-noun-phrases-in-spacy\n",
        "def get_candidates(doc):\n",
        "    # code to recursively combine nouns\n",
        "    # 'We' is actually a pronoun but included in your question\n",
        "    # hence the token.pos_ == \"PRON\" part in the last if statement\n",
        "    # suggest you extract PRON separately like the noun-chunks above\n",
        "\n",
        "    index = 0\n",
        "    noun_indices = [i for i, token in enumerate(doc) if token.pos_ == 'NOUN']\n",
        "    candidates = []\n",
        "    for idxValue in noun_indices:\n",
        "        start = doc[idxValue].left_edge.i if not bool(doc[idxValue].left_edge.ent_type_) else idxValue\n",
        "        finish = doc[idxValue].right_edge.i+1 if not bool(doc[idxValue].right_edge.ent_type_) else idxValue + 1\n",
        "        if 0 < finish-start < 7:\n",
        "            span = doc[start:finish]\n",
        "            candidates.append(span.text)\n",
        "    return candidates\n",
        "\n",
        "candidates = get_candidates(doc)\n",
        "print(candidates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e49affa",
      "metadata": {
        "id": "9e49affa",
        "outputId": "6abc6482-4215-433d-aaae-813c0db7d7c3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "key_model = KeyBERT()\n",
        "keywords = key_model.extract_keywords(doc.text, candidates=candidates, use_mmr=True, diversity=0.5)\n",
        "\n",
        "print(keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d6c720",
      "metadata": {
        "id": "97d6c720",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "* Creating clean text, nouns and keywords from synopsis.\n",
        "* Separate in new df for data analysis.\n",
        "* Delete Syns entries from main df.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c083583",
      "metadata": {
        "id": "0c083583",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df.loc[:, 'nouns'] = df.loc[:,'cleaned_syn'].apply(get_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8020cb36",
      "metadata": {
        "id": "8020cb36",
        "outputId": "882e4530-7cf5-4dc9-e134-d923360eccee",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "syns=['id','title','synopsis','cleaned_syn','nouns']\n",
        "dfsyn=df[syns]\n",
        "dfsyn['genres']=data_main['genres']\n",
        "dfsyn.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ee5cdc",
      "metadata": {
        "id": "24ee5cdc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dropssyn=['synopsis','cleaned_syn','nouns']\n",
        "df=df.drop(dropssyn,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1c5b24",
      "metadata": {
        "id": "be1c5b24",
        "outputId": "a2f6ce6d-2234-41ed-db0e-2640d65187f5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['cleaned_syn'].values[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b61192c",
      "metadata": {
        "id": "8b61192c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn.loc[:, 'doc_clean'] = dfsyn.loc[:,'cleaned_syn'].apply(NLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec82214b",
      "metadata": {
        "id": "ec82214b",
        "outputId": "162b75ce-5dc0-4e97-d107-77488791f1c9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['doc_clean'].values[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b0a558",
      "metadata": {
        "id": "83b0a558",
        "outputId": "988856c4-a5e1-4cc7-a335-22f262477b7c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#dfsyn.drop('cleaned_syn',inplace=True,axis=1)\n",
        "dfsyn.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef0a60d7",
      "metadata": {
        "id": "ef0a60d7",
        "outputId": "a5d20be1-0701-4101-dc59-42ef00545342",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#something weird\n",
        "keyword= [None] * len(dfsyn)\n",
        "docs= [None] * len(dfsyn)\n",
        "for i  in range(len(dfsyn)):\n",
        "    docs[i]= dfsyn[\"doc_clean\"].values[i].text\n",
        "    nouns = dfsyn[\"nouns\"]\n",
        "docs[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d7b014",
      "metadata": {
        "id": "84d7b014",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "for i  in range(len(dfsyn)) :   \n",
        "    keyword[i] = key_model.extract_keywords(docs=docs[i],candidates=nouns.values[i],use_mmr=True, diversity=0.6)\n",
        "keywordunp= [None]* len(keyword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb1a244",
      "metadata": {
        "id": "3fb1a244",
        "outputId": "d8a93b1a-0ccb-4e87-e1a5-1a1fdc353cf8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "for i in range(len(keyword)):\n",
        "\n",
        "        keywordunp[i]=list(itertools.chain(*keyword[i]))\n",
        "        \n",
        "len(keyword),len(keywordunp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939b5467",
      "metadata": {
        "id": "939b5467",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "keywordunp[10]\n",
        "keywords= [1]* len(keyword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d991ed",
      "metadata": {
        "id": "c3d991ed",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(keywordunp)):\n",
        "    for j in range(len(keyword[i])):\n",
        "        keywords[i]=keywordunp[i][0::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3f25ab",
      "metadata": {
        "id": "ca3f25ab",
        "outputId": "4c888ef2-d38f-4a12-a5db-fe1333be854b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "len(keywords),keywords[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311e12cf",
      "metadata": {
        "id": "311e12cf",
        "outputId": "b032b932-fa0a-4534-e14c-a41dd1639b4b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "extracted_keywords=np.array(keywords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d4ae20",
      "metadata": {
        "id": "28d4ae20",
        "outputId": "9d35bf3f-1b89-4de4-f9da-2bb2863cd782",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['keywords']=extracted_keywords.tolist()\n",
        "dfsyn['genres']=data_main['genres']\n",
        "dfsyn['rating']=data_main['rating']\n",
        "dfsyn['media_type']=data_main['media_type']\n",
        "dfsyn.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9db11c",
      "metadata": {
        "id": "9b9db11c",
        "outputId": "120a950a-0f38-4639-8f4e-96f061d9fd75",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0157c56b",
      "metadata": {
        "id": "0157c56b",
        "outputId": "25296436-8e27-4beb-c8db-e817921717ce",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50b2939",
      "metadata": {
        "id": "a50b2939",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#dfsynsave=dfsyn.to_csv(\"../data-history/up-to-date-MAL/anime-synopsis-keywords-nlp.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915f4335",
      "metadata": {
        "id": "915f4335",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## *ii)EDA:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa6177b",
      "metadata": {
        "id": "9fa6177b",
        "outputId": "c2191875-b365-4e34-89db-873939916877",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811268aa",
      "metadata": {
        "id": "811268aa",
        "outputId": "dfff3dde-1360-4e69-aecc-45e9233c751b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"dark\")\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.hist(df['mean'], bins=70,)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0966f7ab",
      "metadata": {
        "id": "0966f7ab",
        "outputId": "bc16d940-38f0-4806-cdda-2ad4b06bd903",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = px.pie(data_main, 'media_type')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da747588",
      "metadata": {
        "id": "da747588",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* Naturally TV has higher percentage as anime media.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4782830d",
      "metadata": {
        "id": "4782830d",
        "outputId": "b0451208-be14-44d0-a866-7c76d296c392",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "corr = data_main.corr()\n",
        "\n",
        "# Set up the matplotlib plot configuration\n",
        "#\n",
        "f, ax = plt.subplots(figsize=(16, 10))\n",
        "#\n",
        "# Generate a mask for upper traingle\n",
        "#\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "#\n",
        "# Configure a custom diverging colormap\n",
        "#\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "#\n",
        "# Draw the heatmap\n",
        "#\n",
        "sns.heatmap(corr, annot=True, mask = mask, cmap=cmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20bd812",
      "metadata": {
        "id": "f20bd812",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:*  So, basically interesting factors that are affecting the mean factor are : rank, popularity, num_scoring_users, ignore num_list_users for now till further investigation of difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406981bb",
      "metadata": {
        "id": "406981bb",
        "outputId": "21fec757-1396-4c6e-c524-f9ceefffa356",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(data_main[data_main['start_date'].dt.year >= 1980], x='start_date', color='media_type')\n",
        "fig.update_layout(bargap=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce618da",
      "metadata": {
        "id": "4ce618da",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* Obviously 2016 was a good year for Otakus :3 specially summer-Autumn-Fall seasons, with 119 tv, 45 movie, 23 ova, 61 ona, 60 special and 41 music. (Gotta check watching list lmao)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5007ddac",
      "metadata": {
        "id": "5007ddac",
        "outputId": "f15d39f1-7604-491e-95c8-5c82de7b805a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.groupby('num_episodes')['id'].count().sort_values(ascending=False).head(30).plot(kind='bar', figsize=(15,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "553dbaad",
      "metadata": {
        "id": "553dbaad",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* A lot of Movies (1 episode) that's why the spike, but the summation of all others are the other percentages of tv,ova,ona,... etc. most tv/specials are short 12 (episodes)/(season|title). </br>\n",
        "*The fans of \"When you have eliminated the impossible\" teenager for 22+ years don't give up :(* </br>\n",
        "*Gomu Gomu no guys don't be Sadge :(*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24b29de",
      "metadata": {
        "id": "e24b29de",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# 2- **MODELS TIME:** :3\n",
        "![image info](https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/gettyimages-458406992-1538405221.jpg?crop=0.9xw:0.9xh;0,0&resize=256:*) <br />\n",
        "  July's 2022 Work"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44e80289",
      "metadata": {
        "id": "44e80289",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Similarity Analysis :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca7a94b",
      "metadata": {
        "id": "1ca7a94b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Synopsis Keyword Analysis:\n",
        "*(NLP)* :\n",
        "* KeyBERT.\n",
        "* Spacy.\n",
        "* tqdm.\n",
        "* CountVectorizer.\n",
        "* TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f89b43",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "27289459ab0c422f8f071039bf1823a1"
          ]
        },
        "id": "28f89b43",
        "outputId": "f2781b46-f5b3-445c-eaed-344c95a34ded",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import sweetviz as sv\n",
        "#You could specify which variable in your dataset is the target for your model creation. We can specify it using the target_feat parameter.\n",
        "data_report = sv.analyze(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d26d21",
      "metadata": {
        "id": "f1d26d21",
        "outputId": "067b8f8d-d220-4c16-9aee-f9527874ebf6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_report.show_notebook(w=1500, h=900, scale=0.8)\n",
        "data_report.show_html(scale=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d88668b",
      "metadata": {
        "id": "4d88668b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Cos-similarity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260b0e86",
      "metadata": {
        "id": "260b0e86",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dedbd7a0",
      "metadata": {
        "id": "dedbd7a0",
        "outputId": "8bd6ef11-5688-4b35-9334-5c1d88d57671",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['synopsis'] + data['genres'] + data['rating'] + data['studios']+data['media_type'])\n",
        "tfidf_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eac98b",
      "metadata": {
        "id": "08eac98b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two movies. \n",
        "\n",
        "$cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89470da8",
      "metadata": {
        "id": "89470da8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d656c42",
      "metadata": {
        "id": "8d656c42",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data = data_main.reset_index()\n",
        "titles = data['title']\n",
        "indices = pd.Series(data_main.index, index=data['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd19b9d5",
      "metadata": {
        "id": "fd19b9d5",
        "outputId": "36e0d9af-9ffd-488d-8e6d-37f637a87f66",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def get_recommendations(title):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cos_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:31]\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "    return titles.iloc[anime_indices]\n",
        "data['title'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e209620e",
      "metadata": {
        "id": "e209620e",
        "outputId": "6e312c15-4196-4c5a-8f8f-33998427c6e2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos_results=get_recommendations('Death Note').head(10)\n",
        "cos_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4106f59b",
      "metadata": {
        "id": "4106f59b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Not so close recommendations but good start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d36b610d",
      "metadata": {
        "id": "d36b610d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### **Featuring keywords and similarities:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7f42a1",
      "metadata": {
        "id": "4a7f42a1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\",\"), binary='true')\n",
        "#vectors=[None]*len(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba93837a",
      "metadata": {
        "id": "ba93837a",
        "outputId": "14a077d2-b065-4a8b-a9df-930b52ebb46e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['keywords'].head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5491d3e5",
      "metadata": {
        "id": "5491d3e5",
        "outputId": "d7f9da91-81a8-4f38-e70f-167512390cd8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4931bbf5",
      "metadata": {
        "id": "4931bbf5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Function to convert all strings to lower case and strip names of spaces\n",
        "def clean_data(x):\n",
        "    if isinstance(x, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "    else:\n",
        "        #Check if director exists. If not, return empty string\n",
        "        if isinstance(x, str):\n",
        "            return str.lower(x.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "# Apply clean_data function to your features.\n",
        "features = ['genres', 'keywords', 'rating', 'media_type']\n",
        "\n",
        "for feature in features:\n",
        "    dfsyn[feature] = dfsyn[feature].apply(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2100730d",
      "metadata": {
        "id": "2100730d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def create_soup(x):\n",
        "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['genres']) + ' ' + x['rating'] + ' ' + ' '.join(x['media_type'])\n",
        "dfsyn['soup'] = dfsyn.apply(create_soup, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f00877",
      "metadata": {
        "id": "66f00877",
        "outputId": "e2004165-08d2-438f-a33b-a50b6163af1b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['soup'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35660f91",
      "metadata": {
        "id": "35660f91",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Function that takes in movie title as input and outputs most similar movies\n",
        "def get_recommendations(title, cosine_sim=cos_sim):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwsie similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cos_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return dfsyn['title'].iloc[anime_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465327c8",
      "metadata": {
        "id": "465327c8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "count = CountVectorizer(stop_words='english')\n",
        "count_matrix = count.fit_transform(dfsyn['soup'])\n",
        "\n",
        "\n",
        "\n",
        "cos_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
        "dfsyn = dfsyn.reset_index()\n",
        "indices = pd.Series(dfsyn.index, index=dfsyn['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b93180a",
      "metadata": {
        "id": "2b93180a",
        "outputId": "be607331-b814-418e-c480-96c81f94fac0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos2_results=get_recommendations('Death Note', cos_sim2)\n",
        "len(cos2_results),cos2_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdc7b0f",
      "metadata": {
        "id": "ffdc7b0f"
      },
      "source": [
        "**Cos-1 is genertated from similarity of multiple features using TF-IDF one of them was the whole synopsis of animes, while Cos2 was using keywords of synopsis instead of the whole synopsis feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40dc3c98",
      "metadata": {
        "id": "40dc3c98",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n",
        "\n",
        "import keras\n",
        "from keras import layers \n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef038ac",
      "metadata": {
        "id": "aef038ac",
        "outputId": "4cac1232-eabb-42dd-ffa0-31f7490a5f2e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf=pd.read_csv(r\"../data-history/ratings-2020/rating_complete.csv\")\n",
        "n = 10\n",
        "\n",
        "# Count the lines or use an upper bound\n",
        "num_lines = sum(1 for l in open(r\"../data-history/ratings-2020/rating_complete.csv\"))\n",
        "\n",
        "# The row indices to skip - make sure 0 is not included to keep the header!\n",
        "skip_idx = [x for x in range(1, num_lines) if x % n != 0]\n",
        "\n",
        "# Read the data\n",
        "#rdf = pd.read_csv(r\"../data-history/ratings-2020/rating_complete.csv\", skiprows=skip_idx )\n",
        "print(rdf.shape)\n",
        "rdf.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe15232",
      "metadata": {
        "id": "8fe15232",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **Pair wise distance** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f17c2b1",
      "metadata": {
        "id": "5f17c2b1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3e6691",
      "metadata": {
        "id": "2f3e6691",
        "outputId": "a1bc107e-7063-4d69-f50d-fb2525107e90",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Removing Duplicated Rows\n",
        "duplicates = rdf.duplicated()\n",
        "\n",
        "if duplicates.sum() > 0:\n",
        "    print('> {} duplicates'.format(duplicates.sum()))\n",
        "    rdf = rdf[~duplicates]\n",
        "\n",
        "print('> {} duplicates'.format(rdf.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd682c1",
      "metadata": {
        "id": "fbd682c1",
        "outputId": "778b38ce-2e51-45a1-82d1-c1c528495195"
      },
      "outputs": [],
      "source": [
        "rdf.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe702214",
      "metadata": {
        "id": "fe702214",
        "outputId": "2ebfc959-661b-400b-9df2-d449908a66ab",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Scaling BTW (0 , 1.0)\n",
        "min_rating = min(rdf['rating'])\n",
        "max_rating = max(rdf['rating'])\n",
        "rdf['rating'] = rdf[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)\n",
        "\n",
        "AvgRating = np.mean(rdf['rating'])\n",
        "print('Avg', AvgRating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5deed892",
      "metadata": {
        "id": "5deed892",
        "outputId": "3f5485b9-c64c-4044-ba88-4682b0223b80",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d226972b",
      "metadata": {
        "id": "d226972b",
        "outputId": "4f1dac20-fcb9-44f9-9db6-676ea37a4820",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "g = rdf.groupby('user_id')['rating'].count()\n",
        "top_users = g.dropna().sort_values(ascending=False)[:20]\n",
        "top_r = rdf.join(top_users, rsuffix='_r', how='inner', on='user_id')\n",
        "\n",
        "g = rdf.groupby('id')['rating'].count()\n",
        "top_animes = g.dropna().sort_values(ascending=False)[:20]\n",
        "top_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='id')\n",
        "\n",
        "pd.crosstab(top_r.user_id, top_r.id, top_r.rating, aggfunc=np.sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38db7008",
      "metadata": {
        "id": "38db7008",
        "outputId": "e36aad91-0421-4b64-eedc-8c1040a87a55"
      },
      "outputs": [],
      "source": [
        "top_r.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e09c93d",
      "metadata": {
        "id": "2e09c93d",
        "outputId": "99d8fb05-30f1-4688-a6c1-1b47b2033bb3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "anime_ids = rdf[\"id\"].unique().tolist()\n",
        "anime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\n",
        "n_animes = len(anime2anime_encoded)\n",
        "anime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\n",
        "\n",
        "rdf[\"anime\"] = rdf[\"id\"].map(anime2anime_encoded)\n",
        "\n",
        "user_ids = rdf[\"user_id\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "user_encoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "n_users = len(user2user_encoded)\n",
        "rdf[\"user\"] = rdf[\"user_id\"].map(user2user_encoded)\n",
        "\n",
        "\n",
        "print(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\n",
        "print(\"Min rating: {}, Max rating: {}\".format(min(rdf['rating']), max(rdf['rating'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b265f2",
      "metadata": {
        "id": "62b265f2",
        "outputId": "ec5948fa-a758-4e2e-8387-1c4c733f05dc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tmatrix = np.zeros((n_users, n_animes))\n",
        "tmatrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c64516",
      "metadata": {
        "id": "32c64516",
        "outputId": "fb711e11-4ef9-41f1-ce53-dab4e9043434",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.columns, rdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61b629d",
      "metadata": {
        "id": "b61b629d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for line in rdf.itertuples():\n",
        "    tmatrix[line[5]-1, line[4]-1] = line[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0f64e7",
      "metadata": {
        "id": "9e0f64e7",
        "outputId": "dfd6415e-0242-4240-f90c-2dbda610fa10",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tmatrix[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626cc751",
      "metadata": {
        "id": "626cc751",
        "outputId": "f7a3a753-094b-44c8-f75b-c735523a0c79",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "user_distances = pairwise_distances(tmatrix, metric=\"cosine\")\n",
        "\n",
        "# \".T\" below is to transpose our 2D matrix.\n",
        "tmatrix_transpose = tmatrix.T\n",
        "anime_distances = pairwise_distances(tmatrix_transpose, metric=\"cosine\")\n",
        "\n",
        "user_distances.shape, anime_distances.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066b8e31",
      "metadata": {
        "id": "066b8e31",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "user_similarity = 1 - user_distances\n",
        "anime_similarity = 1 - anime_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940ec922",
      "metadata": {
        "id": "940ec922",
        "outputId": "87046bb4-ed49-4784-f35f-84023d2680e2"
      },
      "outputs": [],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcde0b0d",
      "metadata": {
        "id": "bcde0b0d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "idx_to_anime = {}\n",
        "for line in data_main.itertuples():\n",
        "        idx_to_anime[(line[1])-1] = line[3]\n",
        "anime_to_idx = {v: k for k, v in idx_to_anime.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c353cbad",
      "metadata": {
        "id": "c353cbad",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "anime_idx= anime_to_idx['Death Note']\n",
        "\n",
        "def top_k_similar(similarity, mapper , anime_idx, k=8):\n",
        "      return [mapper[x] for x in np.argsort(similarity[anime_idx,:])[:-k-2:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de416821",
      "metadata": {
        "id": "de416821",
        "outputId": "a1046e2b-9db9-4409-810b-09296f033091",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "pair_results= top_k_similar(anime_similarity,idx_to_anime ,anime_idx,k=8)\n",
        "print(pair_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03efcae1",
      "metadata": {
        "id": "03efcae1",
        "outputId": "4360ed16-3527-4244-f1c0-0d87eaf729a7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(a, b):\n",
        "    # convert to set\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    # calucate jaccard similarity\n",
        "    j = float(len(a.intersection(b))) / len(a.union(b))\n",
        "    return j\n",
        "print('pair vs cos2')\n",
        "print(jaccard_similarity(pair_results,cos2_results))\n",
        "print('cos1 vs cos2')\n",
        "print(jaccard_similarity(cos_results,cos2_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54189257",
      "metadata": {
        "id": "54189257",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "**zenzen wakaranaaaaaiiiii !!!!!!!!!!!!!** </br>\n",
        ":\"D </br>\n",
        "pair-wise distance results not related to cosine Similarity results at all no intersections. </br>\n",
        "using keywords or using Full synopsis didn't matter for cos similarity so better for resources use keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c378393",
      "metadata": {
        "id": "7c378393",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **RecommendNet Maybe?** :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0b26d0",
      "metadata": {
        "id": "7f0b26d0"
      },
      "source": [
        "**Zenzen heiki janai :\"D , Tasukete, Dare ka tasukeeteeeeee !** <br />\n",
        "  Aug 2022 Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3911afd",
      "metadata": {
        "id": "d3911afd",
        "outputId": "c501f35b-35a4-42d4-d585-24d275e69a83",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.shape,rdf.isnull().sum(),len(rdf['user'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z9s91oGNQ6p_",
      "metadata": {
        "id": "Z9s91oGNQ6p_",
        "outputId": "3e1b562d-c5e6-4c66-fcc0-aeafdf961853",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df.filter(regex='^media_type_',axis=1).head(2), df.filter(regex='^source_',axis=1).head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8729ffa",
      "metadata": {
        "id": "c8729ffa",
        "outputId": "701a8ce5-d428-455a-c823-ee08a647d671",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data['id'].values[1],data['popularity'].values[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247e6f40",
      "metadata": {
        "id": "247e6f40"
      },
      "source": [
        "#### *Normal Recommender features*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c558d803",
      "metadata": {
        "id": "c558d803"
      },
      "source": [
        "**Collaborative Filtering Approach, dependancy on user rates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39f163b",
      "metadata": {
        "id": "e39f163b"
      },
      "outputs": [],
      "source": [
        "# Shuffle\n",
        "rdf = rdf.sample(frac=1, random_state=73)\n",
        "\n",
        "X = rdf[['user', 'anime']].values\n",
        "y = rdf[\"rating\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517d6f95",
      "metadata": {
        "id": "517d6f95",
        "outputId": "8eb0571d-3d67-47c3-dd57-c63f6e17a9b7"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "test_set_size = 10000 #10k for test set\n",
        "train_indices = rdf.shape[0] - test_set_size \n",
        "\n",
        "X_train, X_test, y_train, y_test = (\n",
        "    X[:train_indices],\n",
        "    X[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")\n",
        "\n",
        "print('> Train set ratings: {}'.format(len(y_train)))\n",
        "print('> Test set ratings: {}'.format(len(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8dbfb5",
      "metadata": {
        "id": "7f8dbfb5"
      },
      "outputs": [],
      "source": [
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f12eb13",
      "metadata": {
        "id": "3f12eb13",
        "outputId": "4af83458-4cea-4493-df91-7c7b782d6eb6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbfbd269",
      "metadata": {
        "id": "fbfbd269",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64befe53",
      "metadata": {
        "id": "64befe53",
        "outputId": "e774a17d-a2f4-46cf-81b6-7c6031ee5747",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_train_array[0]))\n",
        "print(len(X_test_array[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf891d75",
      "metadata": {
        "id": "bf891d75",
        "outputId": "c062d6bb-db30-42d3-bcef-9a8e93875928",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def recommender_net():\n",
        "    embedding_size = 64\n",
        "    \n",
        "    user = Input(name = 'user', shape = [1])\n",
        "    user_embedding = Embedding(name = 'user_embedding',\n",
        "                    input_dim = n_users, \n",
        "                    output_dim = embedding_size)(user)\n",
        "    \n",
        "    anime = Input(name = 'anime', shape = [1])\n",
        "    anime_embedding = Embedding(name = 'anime_embedding',\n",
        "                    input_dim = n_animes, \n",
        "                    output_dim = embedding_size)(anime)\n",
        "    #x = Concatenate()([user_embedding, anime_embedding])\n",
        "    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "    model = Model(inputs=[user, anime], outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model1 = recommender_net()\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6883db0c",
      "metadata": {
        "id": "6883db0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6871a874",
      "metadata": {
        "id": "6871a874",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "from tensorflow.python.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005\n",
        "batch_size = 10000\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < rampup_epochs:\n",
        "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "    elif epoch < rampup_epochs + sustain_epochs:\n",
        "        return max_lr\n",
        "    else:\n",
        "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "\n",
        "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n",
        "\n",
        "checkpoint_filepath = './weights.h5'\n",
        "\n",
        "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                            save_weights_only=True,\n",
        "                            monitor='val_loss',\n",
        "                            mode='min',\n",
        "                            save_best_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n",
        "                            mode='min', restore_best_weights=True)\n",
        "\n",
        "my_callbacks = [\n",
        "    model_checkpoints,\n",
        "    lr_callback,\n",
        "    early_stopping,   \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d533cdb7",
      "metadata": {
        "id": "d533cdb7",
        "outputId": "91aec886-4e2f-48ca-858b-3dceea5b0ab3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_test_array[0]))\n",
        "print(len(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0a848e",
      "metadata": {
        "id": "9f0a848e",
        "outputId": "e965f31a-b1ba-459b-87f9-887c6839476d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "history = model1.fit(\n",
        "    x=X_train_array,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test_array, y_test),\n",
        "    callbacks=my_callbacks\n",
        ")\n",
        "\n",
        "model1.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f21adab",
      "metadata": {
        "id": "1f21adab",
        "outputId": "7873c0fb-1e76-4d6c-f952-2bdd5dee5468",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#Training results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history[\"loss\"][0:-2])\n",
        "plt.plot(history.history[\"val_loss\"][0:-2])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a05e281",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "927a943c968d4e0cb24c3746a0eedf41"
          ]
        },
        "id": "7a05e281",
        "outputId": "8ee593ce-3ee7-484d-ce1b-533d616a06aa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "\n",
        "history = model1.fit(\n",
        "    x=X_train_array,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test_array, y_test),\n",
        "    verbose = 0, \n",
        "    callbacks=[TqdmCallback(verbose=0)])\n",
        "\n",
        "model1.load_weights(checkpoint_filepath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87a7a83",
      "metadata": {
        "id": "f87a7a83",
        "outputId": "43567acc-f996-4573-e959-01b266b6d351",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#Training results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history[\"loss\"][0:-2])\n",
        "plt.plot(history.history[\"val_loss\"][0:-2])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04064dde",
      "metadata": {
        "id": "04064dde",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def extract_weights(name, model):\n",
        "    weight_layer = model.get_layer(name)\n",
        "    weights = weight_layer.get_weights()[0]\n",
        "    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n",
        "    return weights\n",
        "\n",
        "anime_weights = extract_weights('anime_embedding', model1)\n",
        "user_weights = extract_weights('user_embedding', model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d50262",
      "metadata": {
        "id": "58d50262",
        "outputId": "4802fff6-b51f-4175-d116-d765076b1d2d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe5d7a7",
      "metadata": {
        "id": "bbe5d7a7",
        "outputId": "898e1150-d462-4e6b-db9d-c02ffbbf373e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "name = data[data_main.id == 100].title.values[0]\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f800769",
      "metadata": {
        "id": "8f800769",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Fixing Names\n",
        "def get_animename(anime_id):\n",
        "    try:\n",
        "        name = data[data_main.id == anime_id].title.values[0]\n",
        "        return name\n",
        "    except:\n",
        "        print('error')\n",
        "        return 0\n",
        "\n",
        "data[\"eng_version\"] = data['title']\n",
        "\n",
        "\n",
        "data_main.sort_values(by=['mean'], \n",
        "                inplace=True,\n",
        "                ascending=False, \n",
        "                kind='quicksort',\n",
        "                na_position='last')\n",
        "\n",
        "df = data[[\"id\",\"title\", \"mean\", \"genres\", \"num_episodes\", \n",
        "        \"media_type\",\"synopsis\"]]\n",
        "\n",
        "\n",
        "def get_animeframe(anime):\n",
        "    if isinstance(anime, int):\n",
        "        return df[df.id == anime]\n",
        "    if isinstance(anime, str):\n",
        "        return df[df.title == anime]\n",
        "def get_sypnopsis(anime):\n",
        "    if isinstance(anime, int):\n",
        "        return df[df.id == anime].synopsis.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9303a7fd",
      "metadata": {
        "id": "9303a7fd",
        "outputId": "1a303010-4a50-472a-c601-ce835de67b1a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871b7023",
      "metadata": {
        "id": "871b7023",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "def find_similar_animes(name, n, return_dist=False, neg=False):\n",
        "        index = get_animeframe(name).id.values[0]\n",
        "        print(index)\n",
        "        encoded_index = anime2anime_encoded.get(index)\n",
        "        weights = anime_weights\n",
        "        print(encoded_index)\n",
        "        dists = np.dot(weights, weights[encoded_index])\n",
        "        sorted_dists = np.argsort(dists)\n",
        "        \n",
        "        n = n + 1            \n",
        "        \n",
        "        if neg:\n",
        "            closest = sorted_dists[:n]\n",
        "        else:\n",
        "            closest = sorted_dists[-n:]\n",
        "        print('animes closest to {}'.format(name))\n",
        "        if return_dist:\n",
        "            return dists, closest\n",
        "        rindex = df\n",
        "        similarityarr = []\n",
        "        for close in closest:\n",
        "            decoded_id = anime_encoded2anime.get(close)\n",
        "            sypnopsis = get_sypnopsis(decoded_id)\n",
        "            anime_frame = get_animeframe(decoded_id)\n",
        "            anime_name = anime_frame.title.values[0]\n",
        "            genre = anime_frame.genres.values[0]\n",
        "            similarity = dists[close]\n",
        "            similarityarr.append({\"id\": decoded_id, \"title\": anime_name,\n",
        "                            \"similarity\": similarity,\"genres\": genre,\n",
        "                            'synopsis': sypnopsis})\n",
        "        frame = pd.Dataframe(similarityarr).sort_values(by=\"similarity\", ascending=False)\n",
        "        return frame[frame.id != index].drop(['id'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5a7329",
      "metadata": {
        "id": "8a5a7329",
        "outputId": "505adc9c-857f-49c8-8c55-7097a0980774",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "find_similar_animes('Death Note', n=10, neg=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a7edce",
      "metadata": {
        "id": "03a7edce"
      },
      "source": [
        "#### *Features modding* <br />\n",
        "   Modifying parameters for Recommend NET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efac23d8",
      "metadata": {
        "id": "efac23d8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# dfdl =pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f6df5b",
      "metadata": {
        "id": "a5f6df5b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# dfdl_ids = data[\"id\"].tolist()\n",
        "# dfdlid_encoded = {x: i for i, x in enumerate(dfdl_ids)}\n",
        "# n_animes = len(dfdlid_encoded)\n",
        "# id_encoded2id = {i: x for i, x in enumerate(dfdl_ids)}\n",
        "# dfdl[\"id\"] = data[\"id\"].map(dfdlid_encoded)\n",
        "\n",
        "# dfdl_mean = data[\"mean\"].tolist()\n",
        "# dfdl_mean_encoded = {x: i for i, x in enumerate(dfdl_mean)}\n",
        "# mean_encoded2mean = {i: x for i, x in enumerate(dfdl_mean)}\n",
        "# n_users = len(dfdl_mean_encoded)\n",
        "# dfdl[\"mean\"] = data[\"mean\"].map(dfdl_mean_encoded)\n",
        "\n",
        "# dfdl_pop = data[\"popularity\"].tolist()\n",
        "# user2user_encoded = {x: i for i, x in enumerate(dfdl_pop)}\n",
        "# user_encoded2user = {i: x for i, x in enumerate(dfdl_pop)}\n",
        "# n_users = len(user2user_encoded)\n",
        "# dfdl[\"popularity\"] = data[\"popularity\"].map(user2user_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12296c98",
      "metadata": {
        "id": "12296c98",
        "outputId": "e529fa72-6a4d-4210-b465-739ccf70e4f2"
      },
      "outputs": [],
      "source": [
        "data_main.columns, data_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d82a86",
      "metadata": {
        "id": "01d82a86",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# x1 = rdf[['user', 'anime']].values \n",
        "\n",
        "# #x2=  data[['id'],['popularity']].values\n",
        "# x3=data[['mean'],['num_scoring_users']].values\n",
        "# x4=data['rank'].tolist(),data['num_favorites'].tolist()\n",
        "# x5= df.filter(regex='^media_type_',axis=1).values[i]\n",
        "# x6= df.filter(regex='^source_',axis=1).values[i]\n",
        "\n",
        "# y = rdf[\"rating\"]\n",
        "# # Split\n",
        "# test_set_size = 250000 #10k for test set\n",
        "# train_indices = rdf_sampled.shape[0] - test_set_size \n",
        "# len(x1),len(x2),len(x2[1]),len(x3),len(x3[1]),len(x4),len(x4[1]),len(y),\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef43819",
      "metadata": {
        "id": "2ef43819",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# X3= x3[:,0] + x3[:,2] +x3[:,3] + x3[:,4] + x3[:,5] + x3[:,1] \n",
        "# X4=['None']*len(x4)*len(x4[1])\n",
        "# for i in range(len(x4[1])):\n",
        "#     X4 =X4 + x4[:,i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e69923",
      "metadata": {
        "id": "45e69923",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# X1_train, X1_test, y_train, y_test = (\n",
        "#     x1[:train_indices],\n",
        "#     x1[train_indices:],\n",
        "#     y[:train_indices],\n",
        "#     y[train_indices:],\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba2e04ac",
      "metadata": {
        "id": "ba2e04ac"
      },
      "source": [
        "### *After Reading Some Articels:*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "073252b3",
      "metadata": {
        "id": "073252b3"
      },
      "source": [
        "#### **Research at home** <br />\n",
        "   Dec. 2022 work <br />\n",
        "\n",
        "Semantic Similarity on synopsis using nlp models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4b48c3",
      "metadata": {
        "id": "af4b48c3"
      },
      "source": [
        "Potential Models for learning: <br />\n",
        "* paraphrase-miniLM\n",
        "* stsb-roberta latest alternatives\n",
        "* bert-base-nli-mean-tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da36912d",
      "metadata": {
        "id": "da36912d"
      },
      "source": [
        "**To_Do:**\n",
        "- Get embeddings from pretrained for all synopsis ( all paragraphs ).\n",
        "- Compare Similarity using distance wise / cosine / pairwise whatever the hell will measure similarity of embeddings.\n",
        "- Worst case senario ,(For each sentence embeddings in the requested anime synopsis loop cosine similarity between all sentences in all other synopsis)\n",
        "- Optimization worth testing: Finding similarity between sentences in the same synopsis to get unique sentences and store those while ignoring sentences that are pretty much similar in embeddings, that leads to having smaller group of sentences for each synopsis to loop on (Still looping bratan).\n",
        "- 5Head IDEA: Semantic Keyword embeddings similarity analysis to get potential chosen titles to do semantic sentence analysis on.\n",
        "- **OR JUST USE PARAPHRASE MINING U Fokin IDIOT, anata BAKA ??? hontoni BAKAAAA.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cilu7XowQ6qE",
      "metadata": {
        "id": "cilu7XowQ6qE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8527b8d",
      "metadata": {
        "id": "b8527b8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "53b5bf601465e97d3bc26103c3f6e93ae804cb5db8486c47b1991b59c7b6e7bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
