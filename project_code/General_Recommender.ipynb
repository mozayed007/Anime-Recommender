{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e07a14e7",
      "metadata": {
        "id": "e07a14e7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **1-Dataset Analysis:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d67f80f",
      "metadata": {
        "id": "3d67f80f",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## *i) Cleaning Dataset:* <br />\n",
        "   Jan 23 Last edits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc326491",
      "metadata": {
        "id": "bc326491"
      },
      "source": [
        "Latest check 30th of Jan. 2023 at 5:00PM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3dcbc79",
      "metadata": {
        "id": "e3dcbc79",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **Importings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b1879af-3046-4b04-ba44-5921bd475314",
      "metadata": {
        "id": "8b1879af-3046-4b04-ba44-5921bd475314",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.express as px\n",
        "from ast import literal_eval\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aa08999a",
      "metadata": {
        "id": "aa08999a",
        "outputId": "95aafdc4-e06b-4dd4-b2f2-8342e14cdc59",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23936, 31)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>media_type</th>\n",
              "      <th>mean</th>\n",
              "      <th>num_scoring_users</th>\n",
              "      <th>status</th>\n",
              "      <th>num_episodes</th>\n",
              "      <th>start_date</th>\n",
              "      <th>end_date</th>\n",
              "      <th>source</th>\n",
              "      <th>...</th>\n",
              "      <th>studios</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>nsfw</th>\n",
              "      <th>created_at</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>main_picture_medium</th>\n",
              "      <th>main_picture_large</th>\n",
              "      <th>alternative_titles_en</th>\n",
              "      <th>alternative_titles_ja</th>\n",
              "      <th>alternative_titles_synonyms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16498</td>\n",
              "      <td>Shingeki no Kyojin</td>\n",
              "      <td>tv</td>\n",
              "      <td>8.53</td>\n",
              "      <td>2585993</td>\n",
              "      <td>finished_airing</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2013-04-07</td>\n",
              "      <td>2013-09-29</td>\n",
              "      <td>manga</td>\n",
              "      <td>...</td>\n",
              "      <td>['Wit Studio']</td>\n",
              "      <td>Centuries ago, mankind was slaughtered to near...</td>\n",
              "      <td>white</td>\n",
              "      <td>2012-12-05 12:03:21</td>\n",
              "      <td>2023-01-12 15:12:07</td>\n",
              "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
              "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
              "      <td>Attack on Titan</td>\n",
              "      <td>進撃の巨人</td>\n",
              "      <td>['AoT', 'SnK']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id               title media_type  mean  num_scoring_users  \\\n",
              "0  16498  Shingeki no Kyojin         tv  8.53            2585993   \n",
              "\n",
              "            status  num_episodes  start_date    end_date source  ...  \\\n",
              "0  finished_airing          25.0  2013-04-07  2013-09-29  manga  ...   \n",
              "\n",
              "          studios                                           synopsis   nsfw  \\\n",
              "0  ['Wit Studio']  Centuries ago, mankind was slaughtered to near...  white   \n",
              "\n",
              "            created_at           updated_at  \\\n",
              "0  2012-12-05 12:03:21  2023-01-12 15:12:07   \n",
              "\n",
              "                                 main_picture_medium  \\\n",
              "0  https://api-cdn.myanimelist.net/images/anime/1...   \n",
              "\n",
              "                                  main_picture_large alternative_titles_en  \\\n",
              "0  https://api-cdn.myanimelist.net/images/anime/1...       Attack on Titan   \n",
              "\n",
              "  alternative_titles_ja alternative_titles_synonyms  \n",
              "0                 進撃の巨人              ['AoT', 'SnK']  \n",
              "\n",
              "[1 rows x 31 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data= pd.read_csv(\"../data-history/up-to-date-MAL/anime_Feb23.csv\")\n",
        "\n",
        "\n",
        "print(data.shape)\n",
        "data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a17cace5",
      "metadata": {
        "id": "a17cace5",
        "outputId": "22e97d4d-74a7-4f81-a869-591f8a93f4b9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season',\n",
              "       'broadcast_day_of_the_week', 'broadcast_start_time', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at',\n",
              "       'main_picture_medium', 'main_picture_large', 'alternative_titles_en',\n",
              "       'alternative_titles_ja', 'alternative_titles_synonyms'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65024cbe",
      "metadata": {
        "id": "65024cbe",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Taking care of nulls and drops:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e9875ecd",
      "metadata": {
        "id": "e9875ecd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "drops=[\"main_picture_medium\",\"main_picture_large\",\"broadcast_day_of_the_week\",\"broadcast_start_time\",\"alternative_titles_en\",\"alternative_titles_ja\",\"alternative_titles_synonyms\"]\n",
        "data_main=data.drop(drops,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8134a3f6",
      "metadata": {
        "id": "8134a3f6",
        "outputId": "9699a8e7-11ff-4610-d112-04874aec5cd9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43697"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(data_main.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c4d0b3e6",
      "metadata": {
        "id": "c4d0b3e6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.fillna(value=data['mean'].mean,inplace=True)\n",
        "data_main.fillna(value=data['rank'].mean,inplace=True)\n",
        "data_main.fillna(value=data['num_favorites'].mean,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "061316ef",
      "metadata": {
        "id": "061316ef",
        "outputId": "1a48fc32-9820-4c80-bcf1-d01b928fa261"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(data_main.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c24d67d4",
      "metadata": {
        "id": "c24d67d4",
        "outputId": "8ae288ba-4fc3-4424-ec59-e57ed2488a14",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(23936, 24)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_main.dropna(subset=['mean','source','num_episodes','start_date','end_date','rank','average_episode_duration','rating','start_season_year','synopsis'],inplace=True)\n",
        "print(sum(data_main.isnull().sum()))\n",
        "print(data_main.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "df0a376e",
      "metadata": {
        "id": "df0a376e",
        "outputId": "4e57dba3-68be-400d-f86b-a7dcf8d354a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                          23936\n",
              "title                       23936\n",
              "media_type                      7\n",
              "mean                          556\n",
              "num_scoring_users            8214\n",
              "status                          3\n",
              "num_episodes                  252\n",
              "start_date                   8224\n",
              "end_date                     8035\n",
              "source                         17\n",
              "num_list_users              10784\n",
              "popularity                  23767\n",
              "num_favorites                1768\n",
              "rank                        21633\n",
              "average_episode_duration     2917\n",
              "rating                          7\n",
              "start_season_year             102\n",
              "start_season_season             5\n",
              "genres                       5282\n",
              "studios                      1488\n",
              "synopsis                    19294\n",
              "nsfw                            2\n",
              "created_at                  23936\n",
              "updated_at                  23903\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0af7069e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b047a3d",
      "metadata": {
        "id": "7b047a3d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Encoding and Adjusting Dtypes:\n",
        " Using separate Data_Frame for reviewing, Yes, Enough ram is available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaeb556",
      "metadata": {
        "id": "feaeb556"
      },
      "source": [
        "###  NLP Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d20d476",
      "metadata": {
        "id": "9d20d476",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### **Applying Key-BERT for Keywords extraction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c33b9a21",
      "metadata": {
        "id": "c33b9a21",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tqdm.notebook import tqdm\n",
        "import ast\n",
        "import re\n",
        "import spacy as sp\n",
        "from keybert import KeyBERT\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ccf05961",
      "metadata": {
        "id": "ccf05961",
        "outputId": "29d4eee1-a44a-49f6-e368-5015ef204cf9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                  Shingeki no Kyojin\n",
              "1                          Death Note\n",
              "2    Fullmetal Alchemist: Brotherhood\n",
              "3                       One Punch Man\n",
              "4                    Sword Art Online\n",
              "5               Boku no Hero Academia\n",
              "6                    Kimetsu no Yaiba\n",
              "7                              Naruto\n",
              "8                         Tokyo Ghoul\n",
              "9              Hunter x Hunter (2011)\n",
              "Name: title, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.title.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a7aa8b92",
      "metadata": {
        "id": "a7aa8b92",
        "outputId": "31b70f93-a7fd-4b94-dd7c-c6bc46b9522b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "brutal murders petty thefts and senseless violence pollute the human world in contrast the realm of death gods is a humdrum unchanging gambling den the ingenious year old japanese student light yagami and sadistic god of death ryuk share one belief their worlds are rotten for his own amusement ryuk drops his death note into the human world light stumbles upon it deeming the first of its rules ridiculous the human whose name is written in this note shall die however the temptation is too great and light experiments by writing a felon s name which disturbingly enacts his first murder aware of the terrifying godlike power that has fallen into his hands light under the alias kira follows his wicked sense of justice with the ultimate goal of cleansing the world of all evil doers the meticulous mastermind detective l is already on his trail but as light s brilliance rivals l s the grand chase for kira turns into an intense battle of wits that can only end when one of them is dead\n"
          ]
        }
      ],
      "source": [
        "NLP = sp.load(\"en_core_web_lg\")\n",
        "TITLE = 'Death Note'\n",
        "key_model = KeyBERT()\n",
        "data_main = data_main[~data_main.title.duplicated(keep='first')]\n",
        "text = data_main[data_main['title'] == TITLE].synopsis.values[0]\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "    text = text.replace('\\n', \"\").replace('\\r', \"\")\n",
        "    text = text.replace('', \"\")\n",
        "    text = re.sub('[^a-zA-Z]', \" \", str(text))\n",
        "    text = ' '.join(text.split())\n",
        "    text = text.lower()\n",
        "    doc = NLP(text)\n",
        "    return doc\n",
        "\n",
        "doc = clean_text(text)\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "75a792fe",
      "metadata": {
        "id": "75a792fe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.loc[:,'cleaned_syn'] = data_main.loc[:,'synopsis'].astype(str).apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "40453053",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at',\n",
              "       'cleaned_syn'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "da40e5b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_string=data_main[['title','synopsis','cleaned_syn']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a86ce1d7",
      "metadata": {
        "id": "a86ce1d7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df_num=pd.get_dummies(data_main, columns=[\"media_type\",\"source\",\"nsfw\",\"genres\",\"rating\",\"studios\"], prefix=[\"media_type\",\"source\",\"nsfw\",\"genres\",\"rating\",\"studios\"])\n",
        "df_num[['id','title','mean','num_scoring_users','num_episodes','popularity','rank']]=data_main[['id','title','mean','num_scoring_users','num_episodes','popularity','rank']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7236910f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((23936, 6822), (23936, 3))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_num.shape,df_string.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bb998201",
      "metadata": {
        "id": "bb998201",
        "outputId": "3382e06a-26d9-4658-814f-77ac25325425",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['brutal murders', 'petty thefts and senseless violence', 'senseless violence', 'the human world', 'contrast', 'the realm of death gods', 'death', 'death gods', 'gambling', 'a humdrum unchanging gambling den', 'ingenious year', 'student', 'light', 'sadistic god', 'their worlds', 'amusement', 'death', 'his death note', 'human world', 'the human world light', 'its rules', 'whose name', 'this note', 'the temptation', 'too great and light experiments', 'a felon s', 'a felon s name', 'his first murder', 'the terrifying godlike power', 'his hands', 'light', 'his wicked sense of justice', 'justice', 'the world of all evil doers', 'all evil doers', 'mastermind', 'the meticulous mastermind detective l', 'l', 'his trail', 'light s', 'light s brilliance', 'the grand chase', 'wits']\n"
          ]
        }
      ],
      "source": [
        "# Based on https://stackoverflow.com/questions/48925328/how-to-get-all-noun-phrases-in-spacy\n",
        "def get_candidates(doc):\n",
        "    # code to recursively combine nouns\n",
        "    # 'We' is actually a pronoun but included in your question\n",
        "    # hence the token.pos_ == \"PRON\" part in the last if statement\n",
        "    # suggest you extract PRON separately like the noun-chunks above\n",
        "\n",
        "    index = 0\n",
        "    noun_indices = [i for i, token in enumerate(doc) if token.pos_ == 'NOUN']\n",
        "    candidates = []\n",
        "    for idxValue in noun_indices:\n",
        "        start = doc[idxValue].left_edge.i if not bool(doc[idxValue].left_edge.ent_type_) else idxValue\n",
        "        finish = doc[idxValue].right_edge.i+1 if not bool(doc[idxValue].right_edge.ent_type_) else idxValue + 1\n",
        "        if 0 < finish-start < 7:\n",
        "            span = doc[start:finish]\n",
        "            candidates.append(span.text)\n",
        "    return candidates\n",
        "\n",
        "candidates = get_candidates(doc)\n",
        "print(candidates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "9e49affa",
      "metadata": {
        "id": "9e49affa",
        "outputId": "6abc6482-4215-433d-aaae-813c0db7d7c3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "key_model = KeyBERT()\n",
        "def get_keywords(doc):\n",
        "    keywords = key_model.extract_keywords(doc.text,keyphrase_ngram_range=(1, 2), candidates=candidates,stop_words='english', use_mmr=True, diversity=0.7)\n",
        "    return keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "80fa69e2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the realm of death gods', 0.5495),\n",
              " ('the meticulous mastermind detective l', 0.4262),\n",
              " ('petty thefts and senseless violence', 0.4666),\n",
              " ('light s', 0.2287),\n",
              " ('its rules', 0.1137)]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_keywords(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d6c720",
      "metadata": {
        "id": "97d6c720",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "* Creating clean text, nouns and keywords from synopsis.\n",
        "* Separate in new df for data analysis.\n",
        "* Delete Syns entries from main df.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0c083583",
      "metadata": {
        "id": "0c083583",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lord MZ\\AppData\\Local\\Temp\\ipykernel_25608\\3548457851.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_string.loc[:,'nouns'] = df_string.loc[:,'cleaned_syn'].apply(get_candidates)\n"
          ]
        }
      ],
      "source": [
        "df_string.loc[:,'nouns'] = df_string.loc[:,'cleaned_syn'].apply(get_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f53034b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lord MZ\\AppData\\Local\\Temp\\ipykernel_25608\\3928247378.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_string.loc[:,'keywords'] = df_string.loc[:,'cleaned_syn'].apply(get_keywords)\n"
          ]
        }
      ],
      "source": [
        "df_string.loc[:,'keywords'] = df_string.loc[:,'cleaned_syn'].apply(get_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "a50b2939",
      "metadata": {
        "id": "a50b2939",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>cleaned_syn</th>\n",
              "      <th>nouns</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2538</th>\n",
              "      <td>Ramen Daisuki Koizumi-san</td>\n",
              "      <td>From standing in the sun for hours to travelin...</td>\n",
              "      <td>(from, standing, in, the, sun, for, hours, to,...</td>\n",
              "      <td>[the sun, hours, miles, home, high school, hig...</td>\n",
              "      <td>[(student, 0.343), (the realm of death gods, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14642</th>\n",
              "      <td>Toumei Shounen Tantei Akira</td>\n",
              "      <td>Akira, a young detective, uses his Invisibilit...</td>\n",
              "      <td>(akira, a, young, detective, uses, his, invisi...</td>\n",
              "      <td>[a young detective, his invisibility, the vill...</td>\n",
              "      <td>[(the meticulous mastermind detective l, 0.381...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19071</th>\n",
              "      <td>Tenka Muteki no Gouyaaman★</td>\n",
              "      <td>A stop-motion music video of bitter melon supe...</td>\n",
              "      <td>(a, stop, motion, music, video, of, bitter, me...</td>\n",
              "      <td>[stop, stop motion, music, melon, bitter melon...</td>\n",
              "      <td>[(the grand chase, 0.216), (sadistic god, 0.12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>Moonrise</td>\n",
              "      <td>Year TS 2XXX AD. Humanity has formed a \"relaxe...</td>\n",
              "      <td>(year, ts, xxx, ad, humanity, has, formed, a, ...</td>\n",
              "      <td>[year, ad, xxx ad humanity, world, a relaxed w...</td>\n",
              "      <td>[(the human world, 0.3024), (a felon s name, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5278</th>\n",
              "      <td>Huyao Xiao Hongniang: Wangquan Fugui</td>\n",
              "      <td>Second season of Huyao Xiao Hongniang.</td>\n",
              "      <td>(second, season, of, huyao, xiao, hongniang)</td>\n",
              "      <td>[season]</td>\n",
              "      <td>[(l, 0.1977), (the realm of death gods, 0.1275...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12394</th>\n",
              "      <td>Tezuka Osamu ga Kieta?! 20 Seiki Saigo no Kaij...</td>\n",
              "      <td>New Year's Eve 2000. An eternally juvenile Tez...</td>\n",
              "      <td>(new, year, s, eve, an, eternally, juvenile, t...</td>\n",
              "      <td>[tezuka, an eternally juvenile tezuka osamu, y...</td>\n",
              "      <td>[(ingenious year, 0.3298), (its rules, 0.0429)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9778</th>\n",
              "      <td>B.B. Fish</td>\n",
              "      <td>At the time of the ceremony of entry to the co...</td>\n",
              "      <td>(at, the, time, of, the, ceremony, of, entry, ...</td>\n",
              "      <td>[entry to the college, the college, a young bo...</td>\n",
              "      <td>[(student, 0.249), (his wicked sense of justic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21453</th>\n",
              "      <td>Internet Overdose</td>\n",
              "      <td>Music video for the song Internet Overdose by ...</td>\n",
              "      <td>(music, video, for, the, song, internet, overd...</td>\n",
              "      <td>[music, music video, internet, the song intern...</td>\n",
              "      <td>[(the temptation, 0.2885), (too great and ligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8557</th>\n",
              "      <td>Yarima Queen</td>\n",
              "      <td>The sorceress Kuri uses her magic to defend he...</td>\n",
              "      <td>(the, sorceress, kuri, uses, her, magic, to, d...</td>\n",
              "      <td>[her magic, perverted monsters and demons, dem...</td>\n",
              "      <td>[(the terrifying godlike power, 0.2668), (its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16058</th>\n",
              "      <td>Gold Pencil And Alien Boy</td>\n",
              "      <td>A Korean animated movie about the boy and his ...</td>\n",
              "      <td>(a, korean, animated, movie, about, the, boy, ...</td>\n",
              "      <td>[his alien friend possessing supernatural powe...</td>\n",
              "      <td>[(the terrifying godlike power, 0.3157), (stud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22274</th>\n",
              "      <td>Youji Shen Bing</td>\n",
              "      <td>&lt;bound method NDFrame._add_numeric_operations....</td>\n",
              "      <td>(bound, method, ndframe, add, numeric, operati...</td>\n",
              "      <td>[bound method ndframe add, numeric operations,...</td>\n",
              "      <td>[(a humdrum unchanging gambling den, 0.0679), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16761</th>\n",
              "      <td>Deko Boko Friends</td>\n",
              "      <td>The creators of Deko Boko Friends, Maruyama Mo...</td>\n",
              "      <td>(the, creators, of, deko, boko, friends, maruy...</td>\n",
              "      <td>[friends, kuwamoto ryoutarou, children, a vari...</td>\n",
              "      <td>[(wits, 0.2193), (its rules, 0.1254), (too gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7881</th>\n",
              "      <td>Lupin III: Touhou Kenbunroku - Another Page</td>\n",
              "      <td>Lupin has become a suspect in the murder of a ...</td>\n",
              "      <td>(lupin, has, become, a, suspect, in, the, murd...</td>\n",
              "      <td>[a professor named theo argent, the professor,...</td>\n",
              "      <td>[(the meticulous mastermind detective l, 0.416...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17656</th>\n",
              "      <td>Nat-chan no Akai Tebukuro</td>\n",
              "      <td>Based on a book by Nishino Ayako.\\n\\nA story a...</td>\n",
              "      <td>(based, on, a, book, by, nishino, ayako, a, st...</td>\n",
              "      <td>[a book, a story, the atomic bomb, schooler, r...</td>\n",
              "      <td>[(the human world light, 0.25), (a felon s nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>Erementar Gerad</td>\n",
              "      <td>After a routine raid, the rookie sky pirate Co...</td>\n",
              "      <td>(after, a, routine, raid, the, rookie, sky, pi...</td>\n",
              "      <td>[a routine raid, the rookie sky pirate, the ro...</td>\n",
              "      <td>[(the meticulous mastermind detective l, 0.286...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8438</th>\n",
              "      <td>Hasande Ageru</td>\n",
              "      <td>&lt;bound method NDFrame._add_numeric_operations....</td>\n",
              "      <td>(bound, method, ndframe, add, numeric, operati...</td>\n",
              "      <td>[bound method ndframe add, numeric operations,...</td>\n",
              "      <td>[(a humdrum unchanging gambling den, 0.0679), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6612</th>\n",
              "      <td>Koukaku Kidoutai Nyuumon Arise</td>\n",
              "      <td>Information show featuring two female characte...</td>\n",
              "      <td>(information, show, featuring, two, female, ch...</td>\n",
              "      <td>[information, the employer of a company, a com...</td>\n",
              "      <td>[(the meticulous mastermind detective l, 0.235...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22695</th>\n",
              "      <td>Yunduo Baobei</td>\n",
              "      <td>&lt;bound method NDFrame._add_numeric_operations....</td>\n",
              "      <td>(bound, method, ndframe, add, numeric, operati...</td>\n",
              "      <td>[bound method ndframe add, numeric operations,...</td>\n",
              "      <td>[(a humdrum unchanging gambling den, 0.0679), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14445</th>\n",
              "      <td>Yuki no Yoru no Yume</td>\n",
              "      <td>A young girl wanders outside on a snowy night,...</td>\n",
              "      <td>(a, young, girl, wanders, outside, on, a, snow...</td>\n",
              "      <td>[a young girl, a snowy night, a place to stay]</td>\n",
              "      <td>[(petty thefts and senseless violence, 0.1458)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4074</th>\n",
              "      <td>Moyashimon Returns</td>\n",
              "      <td>In the second season the story continues exact...</td>\n",
              "      <td>(in, the, second, season, the, story, continue...</td>\n",
              "      <td>[season, the story, professor, professor itsuk...</td>\n",
              "      <td>[(too great and light experiments, 0.2373), (a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "2538                           Ramen Daisuki Koizumi-san   \n",
              "14642                        Toumei Shounen Tantei Akira   \n",
              "19071                         Tenka Muteki no Gouyaaman★   \n",
              "7541                                            Moonrise   \n",
              "5278                Huyao Xiao Hongniang: Wangquan Fugui   \n",
              "12394  Tezuka Osamu ga Kieta?! 20 Seiki Saigo no Kaij...   \n",
              "9778                                           B.B. Fish   \n",
              "21453                                  Internet Overdose   \n",
              "8557                                        Yarima Queen   \n",
              "16058                          Gold Pencil And Alien Boy   \n",
              "22274                                    Youji Shen Bing   \n",
              "16761                                  Deko Boko Friends   \n",
              "7881         Lupin III: Touhou Kenbunroku - Another Page   \n",
              "17656                          Nat-chan no Akai Tebukuro   \n",
              "1962                                     Erementar Gerad   \n",
              "8438                                       Hasande Ageru   \n",
              "6612                      Koukaku Kidoutai Nyuumon Arise   \n",
              "22695                                      Yunduo Baobei   \n",
              "14445                               Yuki no Yoru no Yume   \n",
              "4074                                  Moyashimon Returns   \n",
              "\n",
              "                                                synopsis  \\\n",
              "2538   From standing in the sun for hours to travelin...   \n",
              "14642  Akira, a young detective, uses his Invisibilit...   \n",
              "19071  A stop-motion music video of bitter melon supe...   \n",
              "7541   Year TS 2XXX AD. Humanity has formed a \"relaxe...   \n",
              "5278              Second season of Huyao Xiao Hongniang.   \n",
              "12394  New Year's Eve 2000. An eternally juvenile Tez...   \n",
              "9778   At the time of the ceremony of entry to the co...   \n",
              "21453  Music video for the song Internet Overdose by ...   \n",
              "8557   The sorceress Kuri uses her magic to defend he...   \n",
              "16058  A Korean animated movie about the boy and his ...   \n",
              "22274  <bound method NDFrame._add_numeric_operations....   \n",
              "16761  The creators of Deko Boko Friends, Maruyama Mo...   \n",
              "7881   Lupin has become a suspect in the murder of a ...   \n",
              "17656  Based on a book by Nishino Ayako.\\n\\nA story a...   \n",
              "1962   After a routine raid, the rookie sky pirate Co...   \n",
              "8438   <bound method NDFrame._add_numeric_operations....   \n",
              "6612   Information show featuring two female characte...   \n",
              "22695  <bound method NDFrame._add_numeric_operations....   \n",
              "14445  A young girl wanders outside on a snowy night,...   \n",
              "4074   In the second season the story continues exact...   \n",
              "\n",
              "                                             cleaned_syn  \\\n",
              "2538   (from, standing, in, the, sun, for, hours, to,...   \n",
              "14642  (akira, a, young, detective, uses, his, invisi...   \n",
              "19071  (a, stop, motion, music, video, of, bitter, me...   \n",
              "7541   (year, ts, xxx, ad, humanity, has, formed, a, ...   \n",
              "5278        (second, season, of, huyao, xiao, hongniang)   \n",
              "12394  (new, year, s, eve, an, eternally, juvenile, t...   \n",
              "9778   (at, the, time, of, the, ceremony, of, entry, ...   \n",
              "21453  (music, video, for, the, song, internet, overd...   \n",
              "8557   (the, sorceress, kuri, uses, her, magic, to, d...   \n",
              "16058  (a, korean, animated, movie, about, the, boy, ...   \n",
              "22274  (bound, method, ndframe, add, numeric, operati...   \n",
              "16761  (the, creators, of, deko, boko, friends, maruy...   \n",
              "7881   (lupin, has, become, a, suspect, in, the, murd...   \n",
              "17656  (based, on, a, book, by, nishino, ayako, a, st...   \n",
              "1962   (after, a, routine, raid, the, rookie, sky, pi...   \n",
              "8438   (bound, method, ndframe, add, numeric, operati...   \n",
              "6612   (information, show, featuring, two, female, ch...   \n",
              "22695  (bound, method, ndframe, add, numeric, operati...   \n",
              "14445  (a, young, girl, wanders, outside, on, a, snow...   \n",
              "4074   (in, the, second, season, the, story, continue...   \n",
              "\n",
              "                                                   nouns  \\\n",
              "2538   [the sun, hours, miles, home, high school, hig...   \n",
              "14642  [a young detective, his invisibility, the vill...   \n",
              "19071  [stop, stop motion, music, melon, bitter melon...   \n",
              "7541   [year, ad, xxx ad humanity, world, a relaxed w...   \n",
              "5278                                            [season]   \n",
              "12394  [tezuka, an eternally juvenile tezuka osamu, y...   \n",
              "9778   [entry to the college, the college, a young bo...   \n",
              "21453  [music, music video, internet, the song intern...   \n",
              "8557   [her magic, perverted monsters and demons, dem...   \n",
              "16058  [his alien friend possessing supernatural powe...   \n",
              "22274  [bound method ndframe add, numeric operations,...   \n",
              "16761  [friends, kuwamoto ryoutarou, children, a vari...   \n",
              "7881   [a professor named theo argent, the professor,...   \n",
              "17656  [a book, a story, the atomic bomb, schooler, r...   \n",
              "1962   [a routine raid, the rookie sky pirate, the ro...   \n",
              "8438   [bound method ndframe add, numeric operations,...   \n",
              "6612   [information, the employer of a company, a com...   \n",
              "22695  [bound method ndframe add, numeric operations,...   \n",
              "14445     [a young girl, a snowy night, a place to stay]   \n",
              "4074   [season, the story, professor, professor itsuk...   \n",
              "\n",
              "                                                keywords  \n",
              "2538   [(student, 0.343), (the realm of death gods, 0...  \n",
              "14642  [(the meticulous mastermind detective l, 0.381...  \n",
              "19071  [(the grand chase, 0.216), (sadistic god, 0.12...  \n",
              "7541   [(the human world, 0.3024), (a felon s name, 0...  \n",
              "5278   [(l, 0.1977), (the realm of death gods, 0.1275...  \n",
              "12394  [(ingenious year, 0.3298), (its rules, 0.0429)...  \n",
              "9778   [(student, 0.249), (his wicked sense of justic...  \n",
              "21453  [(the temptation, 0.2885), (too great and ligh...  \n",
              "8557   [(the terrifying godlike power, 0.2668), (its ...  \n",
              "16058  [(the terrifying godlike power, 0.3157), (stud...  \n",
              "22274  [(a humdrum unchanging gambling den, 0.0679), ...  \n",
              "16761  [(wits, 0.2193), (its rules, 0.1254), (too gre...  \n",
              "7881   [(the meticulous mastermind detective l, 0.416...  \n",
              "17656  [(the human world light, 0.25), (a felon s nam...  \n",
              "1962   [(the meticulous mastermind detective l, 0.286...  \n",
              "8438   [(a humdrum unchanging gambling den, 0.0679), ...  \n",
              "6612   [(the meticulous mastermind detective l, 0.235...  \n",
              "22695  [(a humdrum unchanging gambling den, 0.0679), ...  \n",
              "14445  [(petty thefts and senseless violence, 0.1458)...  \n",
              "4074   [(too great and light experiments, 0.2373), (a...  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_string.sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915f4335",
      "metadata": {
        "id": "915f4335",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## *ii)EDA:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "9fa6177b",
      "metadata": {
        "id": "9fa6177b",
        "outputId": "c2191875-b365-4e34-89db-873939916877",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'media_type', 'mean', 'num_scoring_users', 'status',\n",
              "       'num_episodes', 'start_date', 'end_date', 'source', 'num_list_users',\n",
              "       'popularity', 'num_favorites', 'rank', 'average_episode_duration',\n",
              "       'rating', 'start_season_year', 'start_season_season', 'genres',\n",
              "       'studios', 'synopsis', 'nsfw', 'created_at', 'updated_at',\n",
              "       'cleaned_syn'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "11afdf8d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.53"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_main['mean'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "811268aa",
      "metadata": {
        "id": "811268aa",
        "outputId": "dfff3dde-1360-4e69-aecc-45e9233c751b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'<=' not supported between instances of 'float' and 'method'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [69], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sns\u001b[39m.\u001b[39mset_style(\u001b[39m\"\u001b[39m\u001b[39mdark\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39;49mhist(data_main[\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m], bins\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\matplotlib\\pyplot.py:2573\u001b[0m, in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[0;32m   2567\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mhist)\n\u001b[0;32m   2568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhist\u001b[39m(\n\u001b[0;32m   2569\u001b[0m         x, bins\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, density\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m         cumulative\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bottom\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, histtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m, align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2571\u001b[0m         orientation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m, rwidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, log\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2572\u001b[0m         label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stacked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2573\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mhist(\n\u001b[0;32m   2574\u001b[0m         x, bins\u001b[39m=\u001b[39mbins, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m, density\u001b[39m=\u001b[39mdensity, weights\u001b[39m=\u001b[39mweights,\n\u001b[0;32m   2575\u001b[0m         cumulative\u001b[39m=\u001b[39mcumulative, bottom\u001b[39m=\u001b[39mbottom, histtype\u001b[39m=\u001b[39mhisttype,\n\u001b[0;32m   2576\u001b[0m         align\u001b[39m=\u001b[39malign, orientation\u001b[39m=\u001b[39morientation, rwidth\u001b[39m=\u001b[39mrwidth, log\u001b[39m=\u001b[39mlog,\n\u001b[0;32m   2577\u001b[0m         color\u001b[39m=\u001b[39mcolor, label\u001b[39m=\u001b[39mlabel, stacked\u001b[39m=\u001b[39mstacked,\n\u001b[0;32m   2578\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6709\u001b[0m, in \u001b[0;36mAxes.hist\u001b[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[0;32m   6705\u001b[0m \u001b[39mfor\u001b[39;00m xi \u001b[39min\u001b[39;00m x:\n\u001b[0;32m   6706\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xi):\n\u001b[0;32m   6707\u001b[0m         \u001b[39m# python's min/max ignore nan,\u001b[39;00m\n\u001b[0;32m   6708\u001b[0m         \u001b[39m# np.minnan returns nan for all nan input\u001b[39;00m\n\u001b[1;32m-> 6709\u001b[0m         xmin \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(xmin, np\u001b[39m.\u001b[39;49mnanmin(xi))\n\u001b[0;32m   6710\u001b[0m         xmax \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(xmax, np\u001b[39m.\u001b[39mnanmax(xi))\n\u001b[0;32m   6711\u001b[0m \u001b[39mif\u001b[39;00m xmin \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m xmax:  \u001b[39m# Only happens if we have seen a finite value.\u001b[39;00m\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnanmin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:350\u001b[0m, in \u001b[0;36mnanmin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39m# Slow, but safe for subclasses of ndarray\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     a, mask \u001b[39m=\u001b[39m _replace_nan(a, \u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39minf)\n\u001b[1;32m--> 350\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mamin(a, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         \u001b[39mreturn\u001b[39;00m res\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2918\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2802\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[0;32m   2803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2804\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2805\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2806\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[0;32m   2807\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2916\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[0;32m   2917\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2918\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2919\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
            "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'method'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.set_style(\"dark\")\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.hist(data_main['mean'], bins=70)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0966f7ab",
      "metadata": {
        "id": "0966f7ab",
        "outputId": "bc16d940-38f0-4806-cdda-2ad4b06bd903",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = px.pie(data_main, 'media_type')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da747588",
      "metadata": {
        "id": "da747588",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* Naturally TV has higher percentage as anime media.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4782830d",
      "metadata": {
        "id": "4782830d",
        "outputId": "b0451208-be14-44d0-a866-7c76d296c392",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "corr = data_main.corr()\n",
        "\n",
        "# Set up the matplotlib plot configuration\n",
        "#\n",
        "f, ax = plt.subplots(figsize=(16, 10))\n",
        "#\n",
        "# Generate a mask for upper traingle\n",
        "#\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "#\n",
        "# Configure a custom diverging colormap\n",
        "#\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "#\n",
        "# Draw the heatmap\n",
        "#\n",
        "sns.heatmap(corr, annot=True, mask = mask, cmap=cmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20bd812",
      "metadata": {
        "id": "f20bd812",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:*  So, basically interesting factors that are affecting the mean factor are : rank, popularity, num_scoring_users, ignore num_list_users for now till further investigation of difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406981bb",
      "metadata": {
        "id": "406981bb",
        "outputId": "21fec757-1396-4c6e-c524-f9ceefffa356",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(data_main[data_main['start_date'].dt.year >= 1980], x='start_date', color='media_type')\n",
        "fig.update_layout(bargap=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce618da",
      "metadata": {
        "id": "4ce618da",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* Obviously 2016 was a good year for Otakus :3 specially summer-Autumn-Fall seasons, with 119 tv, 45 movie, 23 ova, 61 ona, 60 special and 41 music. (Gotta check watching list lmao)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5007ddac",
      "metadata": {
        "id": "5007ddac",
        "outputId": "f15d39f1-7604-491e-95c8-5c82de7b805a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.groupby('num_episodes')['id'].count().sort_values(ascending=False).head(30).plot(kind='bar', figsize=(15,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "553dbaad",
      "metadata": {
        "id": "553dbaad",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*Notes:* A lot of Movies (1 episode) that's why the spike, but the summation of all others are the other percentages of tv,ova,ona,... etc. most tv/specials are short 12 (episodes)/(season|title). </br>\n",
        "*The fans of \"When you have eliminated the impossible\" teenager for 22+ years don't give up :(* </br>\n",
        "*Gomu Gomu no guys don't be Sadge :(*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24b29de",
      "metadata": {
        "id": "e24b29de",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# 2- **MODELS TIME:** :3\n",
        "![image info](https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/gettyimages-458406992-1538405221.jpg?crop=0.9xw:0.9xh;0,0&resize=256:*) <br />\n",
        "  July's 2022 Work"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44e80289",
      "metadata": {
        "id": "44e80289",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Similarity Analysis :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca7a94b",
      "metadata": {
        "id": "1ca7a94b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Synopsis Keyword Analysis:\n",
        "*(NLP)* :\n",
        "* KeyBERT.\n",
        "* Spacy.\n",
        "* tqdm.\n",
        "* CountVectorizer.\n",
        "* TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f89b43",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "27289459ab0c422f8f071039bf1823a1"
          ]
        },
        "id": "28f89b43",
        "outputId": "f2781b46-f5b3-445c-eaed-344c95a34ded",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import sweetviz as sv\n",
        "#You could specify which variable in your dataset is the target for your model creation. We can specify it using the target_feat parameter.\n",
        "data_report = sv.analyze(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d26d21",
      "metadata": {
        "id": "f1d26d21",
        "outputId": "067b8f8d-d220-4c16-9aee-f9527874ebf6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_report.show_notebook(w=1500, h=900, scale=0.8)\n",
        "data_report.show_html(scale=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d88668b",
      "metadata": {
        "id": "4d88668b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Cos-similarity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260b0e86",
      "metadata": {
        "id": "260b0e86",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dedbd7a0",
      "metadata": {
        "id": "dedbd7a0",
        "outputId": "8bd6ef11-5688-4b35-9334-5c1d88d57671",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['synopsis'] + data['genres'] + data['rating'] + data['studios']+data['media_type'])\n",
        "tfidf_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eac98b",
      "metadata": {
        "id": "08eac98b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two movies. \n",
        "\n",
        "$cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89470da8",
      "metadata": {
        "id": "89470da8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d656c42",
      "metadata": {
        "id": "8d656c42",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data = data_main.reset_index()\n",
        "titles = data['title']\n",
        "indices = pd.Series(data_main.index, index=data['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd19b9d5",
      "metadata": {
        "id": "fd19b9d5",
        "outputId": "36e0d9af-9ffd-488d-8e6d-37f637a87f66",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def get_recommendations(title):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cos_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:31]\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "    return titles.iloc[anime_indices]\n",
        "data['title'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e209620e",
      "metadata": {
        "id": "e209620e",
        "outputId": "6e312c15-4196-4c5a-8f8f-33998427c6e2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos_results=get_recommendations('Death Note').head(10)\n",
        "cos_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4106f59b",
      "metadata": {
        "id": "4106f59b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Not so close recommendations but good start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d36b610d",
      "metadata": {
        "id": "d36b610d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### **Featuring keywords and similarities:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7f42a1",
      "metadata": {
        "id": "4a7f42a1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\",\"), binary='true')\n",
        "#vectors=[None]*len(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba93837a",
      "metadata": {
        "id": "ba93837a",
        "outputId": "14a077d2-b065-4a8b-a9df-930b52ebb46e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['keywords'].head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5491d3e5",
      "metadata": {
        "id": "5491d3e5",
        "outputId": "d7f9da91-81a8-4f38-e70f-167512390cd8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4931bbf5",
      "metadata": {
        "id": "4931bbf5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Function to convert all strings to lower case and strip names of spaces\n",
        "def clean_data(x):\n",
        "    if isinstance(x, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "    else:\n",
        "        #Check if director exists. If not, return empty string\n",
        "        if isinstance(x, str):\n",
        "            return str.lower(x.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "# Apply clean_data function to your features.\n",
        "features = ['genres', 'keywords', 'rating', 'media_type']\n",
        "\n",
        "for feature in features:\n",
        "    dfsyn[feature] = dfsyn[feature].apply(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2100730d",
      "metadata": {
        "id": "2100730d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def create_soup(x):\n",
        "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['genres']) + ' ' + x['rating'] + ' ' + ' '.join(x['media_type'])\n",
        "dfsyn['soup'] = dfsyn.apply(create_soup, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f00877",
      "metadata": {
        "id": "66f00877",
        "outputId": "e2004165-08d2-438f-a33b-a50b6163af1b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dfsyn['soup'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35660f91",
      "metadata": {
        "id": "35660f91",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Function that takes in movie title as input and outputs most similar movies\n",
        "def get_recommendations(title, cosine_sim=cos_sim):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwsie similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cos_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return dfsyn['title'].iloc[anime_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465327c8",
      "metadata": {
        "id": "465327c8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "count = CountVectorizer(stop_words='english')\n",
        "count_matrix = count.fit_transform(dfsyn['soup'])\n",
        "\n",
        "\n",
        "\n",
        "cos_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
        "dfsyn = dfsyn.reset_index()\n",
        "indices = pd.Series(dfsyn.index, index=dfsyn['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b93180a",
      "metadata": {
        "id": "2b93180a",
        "outputId": "be607331-b814-418e-c480-96c81f94fac0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cos2_results=get_recommendations('Death Note', cos_sim2)\n",
        "len(cos2_results),cos2_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdc7b0f",
      "metadata": {
        "id": "ffdc7b0f"
      },
      "source": [
        "**Cos-1 is genertated from similarity of multiple features using TF-IDF one of them was the whole synopsis of animes, while Cos2 was using keywords of synopsis instead of the whole synopsis feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40dc3c98",
      "metadata": {
        "id": "40dc3c98",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n",
        "\n",
        "import keras\n",
        "from keras import layers \n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef038ac",
      "metadata": {
        "id": "aef038ac",
        "outputId": "4cac1232-eabb-42dd-ffa0-31f7490a5f2e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf=pd.read_csv(r\"../data-history/ratings-2020/rating_complete.csv\")\n",
        "n = 10\n",
        "\n",
        "# Count the lines or use an upper bound\n",
        "num_lines = sum(1 for l in open(r\"../data-history/ratings-2020/rating_complete.csv\"))\n",
        "\n",
        "# The row indices to skip - make sure 0 is not included to keep the header!\n",
        "skip_idx = [x for x in range(1, num_lines) if x % n != 0]\n",
        "\n",
        "# Read the data\n",
        "#rdf = pd.read_csv(r\"../data-history/ratings-2020/rating_complete.csv\", skiprows=skip_idx )\n",
        "print(rdf.shape)\n",
        "rdf.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe15232",
      "metadata": {
        "id": "8fe15232",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **Pair wise distance** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f17c2b1",
      "metadata": {
        "id": "5f17c2b1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3e6691",
      "metadata": {
        "id": "2f3e6691",
        "outputId": "a1bc107e-7063-4d69-f50d-fb2525107e90",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Removing Duplicated Rows\n",
        "duplicates = rdf.duplicated()\n",
        "\n",
        "if duplicates.sum() > 0:\n",
        "    print('> {} duplicates'.format(duplicates.sum()))\n",
        "    rdf = rdf[~duplicates]\n",
        "\n",
        "print('> {} duplicates'.format(rdf.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd682c1",
      "metadata": {
        "id": "fbd682c1",
        "outputId": "778b38ce-2e51-45a1-82d1-c1c528495195"
      },
      "outputs": [],
      "source": [
        "rdf.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe702214",
      "metadata": {
        "id": "fe702214",
        "outputId": "2ebfc959-661b-400b-9df2-d449908a66ab",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Scaling BTW (0 , 1.0)\n",
        "min_rating = min(rdf['rating'])\n",
        "max_rating = max(rdf['rating'])\n",
        "rdf['rating'] = rdf[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)\n",
        "\n",
        "AvgRating = np.mean(rdf['rating'])\n",
        "print('Avg', AvgRating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5deed892",
      "metadata": {
        "id": "5deed892",
        "outputId": "3f5485b9-c64c-4044-ba88-4682b0223b80",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d226972b",
      "metadata": {
        "id": "d226972b",
        "outputId": "4f1dac20-fcb9-44f9-9db6-676ea37a4820",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "g = rdf.groupby('user_id')['rating'].count()\n",
        "top_users = g.dropna().sort_values(ascending=False)[:20]\n",
        "top_r = rdf.join(top_users, rsuffix='_r', how='inner', on='user_id')\n",
        "\n",
        "g = rdf.groupby('id')['rating'].count()\n",
        "top_animes = g.dropna().sort_values(ascending=False)[:20]\n",
        "top_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='id')\n",
        "\n",
        "pd.crosstab(top_r.user_id, top_r.id, top_r.rating, aggfunc=np.sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38db7008",
      "metadata": {
        "id": "38db7008",
        "outputId": "e36aad91-0421-4b64-eedc-8c1040a87a55"
      },
      "outputs": [],
      "source": [
        "top_r.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e09c93d",
      "metadata": {
        "id": "2e09c93d",
        "outputId": "99d8fb05-30f1-4688-a6c1-1b47b2033bb3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "anime_ids = rdf[\"id\"].unique().tolist()\n",
        "anime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\n",
        "n_animes = len(anime2anime_encoded)\n",
        "anime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\n",
        "\n",
        "rdf[\"anime\"] = rdf[\"id\"].map(anime2anime_encoded)\n",
        "\n",
        "user_ids = rdf[\"user_id\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "user_encoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "n_users = len(user2user_encoded)\n",
        "rdf[\"user\"] = rdf[\"user_id\"].map(user2user_encoded)\n",
        "\n",
        "\n",
        "print(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\n",
        "print(\"Min rating: {}, Max rating: {}\".format(min(rdf['rating']), max(rdf['rating'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b265f2",
      "metadata": {
        "id": "62b265f2",
        "outputId": "ec5948fa-a758-4e2e-8387-1c4c733f05dc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tmatrix = np.zeros((n_users, n_animes))\n",
        "tmatrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c64516",
      "metadata": {
        "id": "32c64516",
        "outputId": "fb711e11-4ef9-41f1-ce53-dab4e9043434",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.columns, rdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61b629d",
      "metadata": {
        "id": "b61b629d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for line in rdf.itertuples():\n",
        "    tmatrix[line[5]-1, line[4]-1] = line[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0f64e7",
      "metadata": {
        "id": "9e0f64e7",
        "outputId": "dfd6415e-0242-4240-f90c-2dbda610fa10",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tmatrix[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626cc751",
      "metadata": {
        "id": "626cc751",
        "outputId": "f7a3a753-094b-44c8-f75b-c735523a0c79",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "user_distances = pairwise_distances(tmatrix, metric=\"cosine\")\n",
        "\n",
        "# \".T\" below is to transpose our 2D matrix.\n",
        "tmatrix_transpose = tmatrix.T\n",
        "anime_distances = pairwise_distances(tmatrix_transpose, metric=\"cosine\")\n",
        "\n",
        "user_distances.shape, anime_distances.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066b8e31",
      "metadata": {
        "id": "066b8e31",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "user_similarity = 1 - user_distances\n",
        "anime_similarity = 1 - anime_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940ec922",
      "metadata": {
        "id": "940ec922",
        "outputId": "87046bb4-ed49-4784-f35f-84023d2680e2"
      },
      "outputs": [],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcde0b0d",
      "metadata": {
        "id": "bcde0b0d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "idx_to_anime = {}\n",
        "for line in data_main.itertuples():\n",
        "        idx_to_anime[(line[1])-1] = line[3]\n",
        "anime_to_idx = {v: k for k, v in idx_to_anime.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c353cbad",
      "metadata": {
        "id": "c353cbad",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "anime_idx= anime_to_idx['Death Note']\n",
        "\n",
        "def top_k_similar(similarity, mapper , anime_idx, k=8):\n",
        "      return [mapper[x] for x in np.argsort(similarity[anime_idx,:])[:-k-2:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de416821",
      "metadata": {
        "id": "de416821",
        "outputId": "a1046e2b-9db9-4409-810b-09296f033091",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "pair_results= top_k_similar(anime_similarity,idx_to_anime ,anime_idx,k=8)\n",
        "print(pair_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03efcae1",
      "metadata": {
        "id": "03efcae1",
        "outputId": "4360ed16-3527-4244-f1c0-0d87eaf729a7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(a, b):\n",
        "    # convert to set\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    # calucate jaccard similarity\n",
        "    j = float(len(a.intersection(b))) / len(a.union(b))\n",
        "    return j\n",
        "print('pair vs cos2')\n",
        "print(jaccard_similarity(pair_results,cos2_results))\n",
        "print('cos1 vs cos2')\n",
        "print(jaccard_similarity(cos_results,cos2_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54189257",
      "metadata": {
        "id": "54189257",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "**zenzen wakaranaaaaaiiiii !!!!!!!!!!!!!** </br>\n",
        ":\"D </br>\n",
        "pair-wise distance results not related to cosine Similarity results at all no intersections. </br>\n",
        "using keywords or using Full synopsis didn't matter for cos similarity so better for resources use keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c378393",
      "metadata": {
        "id": "7c378393",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### **RecommendNet Maybe?** :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0b26d0",
      "metadata": {
        "id": "7f0b26d0"
      },
      "source": [
        "**Zenzen heiki janai :\"D , Tasukete, Dare ka tasukeeteeeeee !** <br />\n",
        "  Aug 2022 Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3911afd",
      "metadata": {
        "id": "d3911afd",
        "outputId": "c501f35b-35a4-42d4-d585-24d275e69a83",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "rdf.shape,rdf.isnull().sum(),len(rdf['user'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z9s91oGNQ6p_",
      "metadata": {
        "id": "Z9s91oGNQ6p_",
        "outputId": "3e1b562d-c5e6-4c66-fcc0-aeafdf961853",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df.filter(regex='^media_type_',axis=1).head(2), df.filter(regex='^source_',axis=1).head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8729ffa",
      "metadata": {
        "id": "c8729ffa",
        "outputId": "701a8ce5-d428-455a-c823-ee08a647d671",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data['id'].values[1],data['popularity'].values[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247e6f40",
      "metadata": {
        "id": "247e6f40"
      },
      "source": [
        "#### *Normal Recommender features*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c558d803",
      "metadata": {
        "id": "c558d803"
      },
      "source": [
        "**Collaborative Filtering Approach, dependancy on user rates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39f163b",
      "metadata": {
        "id": "e39f163b"
      },
      "outputs": [],
      "source": [
        "# Shuffle\n",
        "rdf = rdf.sample(frac=1, random_state=73)\n",
        "\n",
        "X = rdf[['user', 'anime']].values\n",
        "y = rdf[\"rating\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517d6f95",
      "metadata": {
        "id": "517d6f95",
        "outputId": "8eb0571d-3d67-47c3-dd57-c63f6e17a9b7"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "test_set_size = 10000 #10k for test set\n",
        "train_indices = rdf.shape[0] - test_set_size \n",
        "\n",
        "X_train, X_test, y_train, y_test = (\n",
        "    X[:train_indices],\n",
        "    X[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")\n",
        "\n",
        "print('> Train set ratings: {}'.format(len(y_train)))\n",
        "print('> Test set ratings: {}'.format(len(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8dbfb5",
      "metadata": {
        "id": "7f8dbfb5"
      },
      "outputs": [],
      "source": [
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f12eb13",
      "metadata": {
        "id": "3f12eb13",
        "outputId": "4af83458-4cea-4493-df91-7c7b782d6eb6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbfbd269",
      "metadata": {
        "id": "fbfbd269",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64befe53",
      "metadata": {
        "id": "64befe53",
        "outputId": "e774a17d-a2f4-46cf-81b6-7c6031ee5747",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_train_array[0]))\n",
        "print(len(X_test_array[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf891d75",
      "metadata": {
        "id": "bf891d75",
        "outputId": "c062d6bb-db30-42d3-bcef-9a8e93875928",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def recommender_net():\n",
        "    embedding_size = 64\n",
        "    \n",
        "    user = Input(name = 'user', shape = [1])\n",
        "    user_embedding = Embedding(name = 'user_embedding',\n",
        "                    input_dim = n_users, \n",
        "                    output_dim = embedding_size)(user)\n",
        "    \n",
        "    anime = Input(name = 'anime', shape = [1])\n",
        "    anime_embedding = Embedding(name = 'anime_embedding',\n",
        "                    input_dim = n_animes, \n",
        "                    output_dim = embedding_size)(anime)\n",
        "    #x = Concatenate()([user_embedding, anime_embedding])\n",
        "    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "    model = Model(inputs=[user, anime], outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model1 = recommender_net()\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6883db0c",
      "metadata": {
        "id": "6883db0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6871a874",
      "metadata": {
        "id": "6871a874",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "from tensorflow.python.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005\n",
        "batch_size = 10000\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < rampup_epochs:\n",
        "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "    elif epoch < rampup_epochs + sustain_epochs:\n",
        "        return max_lr\n",
        "    else:\n",
        "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "\n",
        "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n",
        "\n",
        "checkpoint_filepath = './weights.h5'\n",
        "\n",
        "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                            save_weights_only=True,\n",
        "                            monitor='val_loss',\n",
        "                            mode='min',\n",
        "                            save_best_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n",
        "                            mode='min', restore_best_weights=True)\n",
        "\n",
        "my_callbacks = [\n",
        "    model_checkpoints,\n",
        "    lr_callback,\n",
        "    early_stopping,   \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d533cdb7",
      "metadata": {
        "id": "d533cdb7",
        "outputId": "91aec886-4e2f-48ca-858b-3dceea5b0ab3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(X_test_array[0]))\n",
        "print(len(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0a848e",
      "metadata": {
        "id": "9f0a848e",
        "outputId": "e965f31a-b1ba-459b-87f9-887c6839476d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "history = model1.fit(\n",
        "    x=X_train_array,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test_array, y_test),\n",
        "    callbacks=my_callbacks\n",
        ")\n",
        "\n",
        "model1.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f21adab",
      "metadata": {
        "id": "1f21adab",
        "outputId": "7873c0fb-1e76-4d6c-f952-2bdd5dee5468",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#Training results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history[\"loss\"][0:-2])\n",
        "plt.plot(history.history[\"val_loss\"][0:-2])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a05e281",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "927a943c968d4e0cb24c3746a0eedf41"
          ]
        },
        "id": "7a05e281",
        "outputId": "8ee593ce-3ee7-484d-ce1b-533d616a06aa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm.keras import TqdmCallback\n",
        "\n",
        "\n",
        "history = model1.fit(\n",
        "    x=X_train_array,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test_array, y_test),\n",
        "    verbose = 0, \n",
        "    callbacks=[TqdmCallback(verbose=0)])\n",
        "\n",
        "model1.load_weights(checkpoint_filepath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87a7a83",
      "metadata": {
        "id": "f87a7a83",
        "outputId": "43567acc-f996-4573-e959-01b266b6d351",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#Training results\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history[\"loss\"][0:-2])\n",
        "plt.plot(history.history[\"val_loss\"][0:-2])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04064dde",
      "metadata": {
        "id": "04064dde",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def extract_weights(name, model):\n",
        "    weight_layer = model.get_layer(name)\n",
        "    weights = weight_layer.get_weights()[0]\n",
        "    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n",
        "    return weights\n",
        "\n",
        "anime_weights = extract_weights('anime_embedding', model1)\n",
        "user_weights = extract_weights('user_embedding', model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d50262",
      "metadata": {
        "id": "58d50262",
        "outputId": "4802fff6-b51f-4175-d116-d765076b1d2d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "data_main.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe5d7a7",
      "metadata": {
        "id": "bbe5d7a7",
        "outputId": "898e1150-d462-4e6b-db9d-c02ffbbf373e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "name = data[data_main.id == 100].title.values[0]\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f800769",
      "metadata": {
        "id": "8f800769",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Fixing Names\n",
        "def get_animename(anime_id):\n",
        "    try:\n",
        "        name = data[data_main.id == anime_id].title.values[0]\n",
        "        return name\n",
        "    except:\n",
        "        print('error')\n",
        "        return 0\n",
        "\n",
        "data[\"eng_version\"] = data['title']\n",
        "\n",
        "\n",
        "data_main.sort_values(by=['mean'], \n",
        "                inplace=True,\n",
        "                ascending=False, \n",
        "                kind='quicksort',\n",
        "                na_position='last')\n",
        "\n",
        "df = data[[\"id\",\"title\", \"mean\", \"genres\", \"num_episodes\", \n",
        "        \"media_type\",\"synopsis\"]]\n",
        "\n",
        "\n",
        "def get_animeframe(anime):\n",
        "    if isinstance(anime, int):\n",
        "        return df[df.id == anime]\n",
        "    if isinstance(anime, str):\n",
        "        return df[df.title == anime]\n",
        "def get_sypnopsis(anime):\n",
        "    if isinstance(anime, int):\n",
        "        return df[df.id == anime].synopsis.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9303a7fd",
      "metadata": {
        "id": "9303a7fd",
        "outputId": "1a303010-4a50-472a-c601-ce835de67b1a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871b7023",
      "metadata": {
        "id": "871b7023",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "def find_similar_animes(name, n, return_dist=False, neg=False):\n",
        "        index = get_animeframe(name).id.values[0]\n",
        "        print(index)\n",
        "        encoded_index = anime2anime_encoded.get(index)\n",
        "        weights = anime_weights\n",
        "        print(encoded_index)\n",
        "        dists = np.dot(weights, weights[encoded_index])\n",
        "        sorted_dists = np.argsort(dists)\n",
        "        \n",
        "        n = n + 1            \n",
        "        \n",
        "        if neg:\n",
        "            closest = sorted_dists[:n]\n",
        "        else:\n",
        "            closest = sorted_dists[-n:]\n",
        "        print('animes closest to {}'.format(name))\n",
        "        if return_dist:\n",
        "            return dists, closest\n",
        "        rindex = df\n",
        "        similarityarr = []\n",
        "        for close in closest:\n",
        "            decoded_id = anime_encoded2anime.get(close)\n",
        "            sypnopsis = get_sypnopsis(decoded_id)\n",
        "            anime_frame = get_animeframe(decoded_id)\n",
        "            anime_name = anime_frame.title.values[0]\n",
        "            genre = anime_frame.genres.values[0]\n",
        "            similarity = dists[close]\n",
        "            similarityarr.append({\"id\": decoded_id, \"title\": anime_name,\n",
        "                            \"similarity\": similarity,\"genres\": genre,\n",
        "                            'synopsis': sypnopsis})\n",
        "        frame = pd.Dataframe(similarityarr).sort_values(by=\"similarity\", ascending=False)\n",
        "        return frame[frame.id != index].drop(['id'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5a7329",
      "metadata": {
        "id": "8a5a7329",
        "outputId": "505adc9c-857f-49c8-8c55-7097a0980774",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "find_similar_animes('Death Note', n=10, neg=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a7edce",
      "metadata": {
        "id": "03a7edce"
      },
      "source": [
        "#### *Features modding* <br />\n",
        "   Modifying parameters for Recommend NET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efac23d8",
      "metadata": {
        "id": "efac23d8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# dfdl =pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f6df5b",
      "metadata": {
        "id": "a5f6df5b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# dfdl_ids = data[\"id\"].tolist()\n",
        "# dfdlid_encoded = {x: i for i, x in enumerate(dfdl_ids)}\n",
        "# n_animes = len(dfdlid_encoded)\n",
        "# id_encoded2id = {i: x for i, x in enumerate(dfdl_ids)}\n",
        "# dfdl[\"id\"] = data[\"id\"].map(dfdlid_encoded)\n",
        "\n",
        "# dfdl_mean = data[\"mean\"].tolist()\n",
        "# dfdl_mean_encoded = {x: i for i, x in enumerate(dfdl_mean)}\n",
        "# mean_encoded2mean = {i: x for i, x in enumerate(dfdl_mean)}\n",
        "# n_users = len(dfdl_mean_encoded)\n",
        "# dfdl[\"mean\"] = data[\"mean\"].map(dfdl_mean_encoded)\n",
        "\n",
        "# dfdl_pop = data[\"popularity\"].tolist()\n",
        "# user2user_encoded = {x: i for i, x in enumerate(dfdl_pop)}\n",
        "# user_encoded2user = {i: x for i, x in enumerate(dfdl_pop)}\n",
        "# n_users = len(user2user_encoded)\n",
        "# dfdl[\"popularity\"] = data[\"popularity\"].map(user2user_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12296c98",
      "metadata": {
        "id": "12296c98",
        "outputId": "e529fa72-6a4d-4210-b465-739ccf70e4f2"
      },
      "outputs": [],
      "source": [
        "data_main.columns, data_main.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d82a86",
      "metadata": {
        "id": "01d82a86",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# x1 = rdf[['user', 'anime']].values \n",
        "\n",
        "# #x2=  data[['id'],['popularity']].values\n",
        "# x3=data[['mean'],['num_scoring_users']].values\n",
        "# x4=data['rank'].tolist(),data['num_favorites'].tolist()\n",
        "# x5= df.filter(regex='^media_type_',axis=1).values[i]\n",
        "# x6= df.filter(regex='^source_',axis=1).values[i]\n",
        "\n",
        "# y = rdf[\"rating\"]\n",
        "# # Split\n",
        "# test_set_size = 250000 #10k for test set\n",
        "# train_indices = rdf_sampled.shape[0] - test_set_size \n",
        "# len(x1),len(x2),len(x2[1]),len(x3),len(x3[1]),len(x4),len(x4[1]),len(y),\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef43819",
      "metadata": {
        "id": "2ef43819",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# X3= x3[:,0] + x3[:,2] +x3[:,3] + x3[:,4] + x3[:,5] + x3[:,1] \n",
        "# X4=['None']*len(x4)*len(x4[1])\n",
        "# for i in range(len(x4[1])):\n",
        "#     X4 =X4 + x4[:,i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e69923",
      "metadata": {
        "id": "45e69923",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# X1_train, X1_test, y_train, y_test = (\n",
        "#     x1[:train_indices],\n",
        "#     x1[train_indices:],\n",
        "#     y[:train_indices],\n",
        "#     y[train_indices:],\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba2e04ac",
      "metadata": {
        "id": "ba2e04ac"
      },
      "source": [
        "### *After Reading Some Articels:*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "073252b3",
      "metadata": {
        "id": "073252b3"
      },
      "source": [
        "#### **Research at home** <br />\n",
        "   Dec. 2022 work <br />\n",
        "\n",
        "Semantic Similarity on synopsis using nlp models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4b48c3",
      "metadata": {
        "id": "af4b48c3"
      },
      "source": [
        "Potential Models for learning: <br />\n",
        "* paraphrase-miniLM\n",
        "* stsb-roberta latest alternatives\n",
        "* bert-base-nli-mean-tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da36912d",
      "metadata": {
        "id": "da36912d"
      },
      "source": [
        "**To_Do:**\n",
        "- Get embeddings from pretrained for all synopsis ( all paragraphs ).\n",
        "- Compare Similarity using distance wise / cosine / pairwise whatever the hell will measure similarity of embeddings.\n",
        "- Worst case senario ,(For each sentence embeddings in the requested anime synopsis loop cosine similarity between all sentences in all other synopsis)\n",
        "- Optimization worth testing: Finding similarity between sentences in the same synopsis to get unique sentences and store those while ignoring sentences that are pretty much similar in embeddings, that leads to having smaller group of sentences for each synopsis to loop on (Still looping bratan).\n",
        "- 5Head IDEA: Semantic Keyword embeddings similarity analysis to get potential chosen titles to do semantic sentence analysis on.\n",
        "- **OR JUST USE PARAPHRASE MINING U Fokin IDIOT, anata BAKA ??? hontoni BAKAAAA.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cilu7XowQ6qE",
      "metadata": {
        "id": "cilu7XowQ6qE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8527b8d",
      "metadata": {
        "id": "b8527b8d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "53b5bf601465e97d3bc26103c3f6e93ae804cb5db8486c47b1991b59c7b6e7bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
