{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAL API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_url = 'https://api.myanimelist.net/v2'\n",
    "\n",
    "# A Client ID is needed (https://myanimelist.net/apiconfig)\n",
    "#with open('client_id.txt', 'r') as f:\n",
    "#    CLIENT_ID = f.read()\n",
    "\n",
    "headers = {'X-MAL-CLIENT-ID': \"(Put your client ID here)\"}\n",
    "\n",
    "def get_data(endpoint, params=None):\n",
    "    url = api_url + endpoint\n",
    "    if params:\n",
    "        url += '?' + '&'.join(f'{key}={value}' for key, value in params.items())\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "scraping_save_pages = '../My Anime List Scrapping/data/data_tmp/anime_pages'\n",
    "\n",
    "if not os.path.exists(scraping_save_pages): # Create saving directory if it doesn't exist\n",
    "  os.makedirs(scraping_save_pages)\n",
    "\n",
    "endpoint = f'/anime/ranking'\n",
    "limit = 500\n",
    "\n",
    "anime_keys = ['id', 'title', 'main_picture', 'alternative_titles', 'start_date', 'end_date', 'synopsis', 'mean', 'rank', 'popularity',\n",
    "              'num_list_users', 'num_scoring_users', 'num_favorites', 'nsfw', 'genres', 'created_at', 'updated_at', 'media_type', 'status',\n",
    "              'num_episodes', 'start_season', 'broadcast', 'source', 'average_episode_duration', 'rating','studios','recommendation''node']\n",
    "\n",
    "def scrape_page(page):\n",
    "    params = {'ranking_type': 'bypopularity', 'limit': limit, 'offset': page*limit, 'fields': ','.join(anime_keys)}\n",
    "    data = get_data(endpoint, params)\n",
    "    useful = [anime['node'] for anime in data['data']]\n",
    "    with open(scraping_save_pages + f'/page{str(page).zfill(2)}.json', 'w') as f:\n",
    "        json.dump(useful, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 12 July 2022\n",
    "previous_total_anime = 20_741\n",
    "previous_last_page = math.ceil(previous_total_anime / limit) - 1\n",
    "\n",
    "data = get_data(endpoint, {'ranking_type': 'bypopularity', 'limit': limit, 'offset': previous_last_page*limit, 'fields': ','.join(anime_keys)})\n",
    "#data = get_data(endpoint,{'ranking_type': 'bypopularity', 'limit': limit, 'offset': previous_last_page*limit, 'fields': ','.join(str(v) for v in 'recommendations')})\n",
    "assert len(data['data']) > 0\n",
    "assert 'next' not in data['paging']\n",
    "\n",
    "\n",
    "last_page = previous_last_page\n",
    "\n",
    "last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:03<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import time\n",
    "\n",
    "for page in tqdm.trange(last_page+1):\n",
    "    scrape_page(page)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23861, list)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "scraping_save_pages = 'data/data_tmp/anime_pages'\n",
    "\n",
    "data = []\n",
    "for file_name in os.listdir(scraping_save_pages):\n",
    "    file_path = os.path.join(scraping_save_pages, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    data.extend(file)\n",
    "\n",
    "len(data),type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1535,\n",
       " 'title': 'Death Note',\n",
       " 'main_picture': {'medium': 'https://api-cdn.myanimelist.net/images/anime/9/9453.jpg',\n",
       "  'large': 'https://api-cdn.myanimelist.net/images/anime/9/9453l.jpg'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data),len(data[1])\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_tmp/anime_raw.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'recommendations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recommendations'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mm:\\Anime Recommender\\My Anime List Scrapping\\anime.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Anime%20Recommender/My%20Anime%20List%20Scrapping/anime.ipynb#ch0000010?line=27'>28</a>\u001b[0m \u001b[39m# Only keep names\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Anime%20Recommender/My%20Anime%20List%20Scrapping/anime.ipynb#ch0000010?line=28'>29</a>\u001b[0m anime[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m anime[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [dic[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m dic \u001b[39min\u001b[39;00m x] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan \u001b[39melse\u001b[39;00m [])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/Anime%20Recommender/My%20Anime%20List%20Scrapping/anime.ipynb#ch0000010?line=29'>30</a>\u001b[0m anime[\u001b[39m'\u001b[39m\u001b[39mrecommendations\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m anime[\u001b[39m'\u001b[39;49m\u001b[39mrecommendations\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [dic[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m dic \u001b[39min\u001b[39;00m x] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan \u001b[39melse\u001b[39;00m [])\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Anime%20Recommender/My%20Anime%20List%20Scrapping/anime.ipynb#ch0000010?line=30'>31</a>\u001b[0m anime[\u001b[39m'\u001b[39m\u001b[39mstudios\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m anime[\u001b[39m'\u001b[39m\u001b[39mstudios\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [dic[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m dic \u001b[39min\u001b[39;00m x] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan \u001b[39melse\u001b[39;00m [])\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Anime%20Recommender/My%20Anime%20List%20Scrapping/anime.ipynb#ch0000010?line=31'>32</a>\u001b[0m anime[\u001b[39m'\u001b[39m\u001b[39mrecommendations\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m anime[\u001b[39m'\u001b[39m\u001b[39mrecommendations\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [dic[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m dic \u001b[39min\u001b[39;00m x] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan \u001b[39melse\u001b[39;00m [])\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recommendations'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open('data/data_tmp/anime_raw.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "anime = pd.json_normalize(data, sep='_')\n",
    "\n",
    "# Use Timestamps\n",
    "anime['start_date'] = pd.to_datetime(anime['start_date'])\n",
    "anime['end_date'] = pd.to_datetime(anime['end_date'])\n",
    "\n",
    "# Avoid floats and zeroes marking nsfw\n",
    "anime['num_episodes'] = anime['num_episodes'].replace(0, np.nan).astype('Int64')\n",
    "anime['popularity'] = anime['popularity'].replace(0, np.nan).astype('Int64')\n",
    "anime['rank'] = anime['rank'].replace(0, np.nan).astype('Int64')\n",
    "anime['mean'] = anime['mean'].replace(0, np.nan).astype('float64')\n",
    "anime['num_favorites'] = anime['num_favorites'].replace(0, np.nan).astype('Int64')\n",
    "\n",
    "# Use Timedelta\n",
    "anime['average_episode_duration'] = pd.to_timedelta(anime['average_episode_duration'].replace(0, np.nan), unit='s')\n",
    "\n",
    "# Avoid floats, as time\n",
    "anime['start_season_year'] = anime['start_season_year'].astype('Int64')\n",
    "anime['broadcast_start_time'] = pd.to_datetime(anime['broadcast_start_time']).dt.time\n",
    "\n",
    "# Only keep names\n",
    "anime['genres'] = anime['genres'].apply(lambda x: [dic['name'] for dic in x] if not x is np.nan else [])\n",
    "anime['recommendations'] = anime['recommendations'].apply(lambda x: [dic['title'] for dic in x] if not x is np.nan else [])\n",
    "anime['studios'] = anime['studios'].apply(lambda x: [dic['name'] for dic in x] if not x is np.nan else [])\n",
    "anime['recommendations'] = anime['recommendations'].apply(lambda x: [dic['name'] for dic in x] if not x is np.nan else [])\n",
    "# MyAnimeList edits\n",
    "anime['created_at'] = pd.to_datetime(anime['created_at']).dt.tz_convert(None)\n",
    "anime['updated_at'] = pd.to_datetime(anime['updated_at']).dt.tz_convert(None)\n",
    "\n",
    "# Avoid empty string\n",
    "anime['synopsis'] = anime['synopsis'].replace('', np.nan)\n",
    "anime['recommendations'] = anime['recommendations'].replace('', np.nan)\n",
    "anime['alternative_titles_en'] = anime['alternative_titles_en'].replace('', np.nan)\n",
    "anime['alternative_titles_ja'] = anime['alternative_titles_ja'].replace('', np.nan)\n",
    "                \n",
    "\n",
    "order = ['id', 'title', 'media_type', 'mean', 'num_scoring_users',                          # 10 Most important attributes, \n",
    "        'status', 'num_episodes', 'start_date', 'end_date', 'source',                      # appearing first on kaggle\n",
    "\n",
    "        'num_list_users', 'popularity', 'num_favorites', 'rank',                           # Other important\n",
    "        'average_episode_duration', 'rating', 'start_season_year',                         # attributes\n",
    "        'start_season_season', 'broadcast_day_of_the_week', 'broadcast_start_time',   \n",
    "\n",
    "        'genres', 'studios',                                                               # Multivalued attributes\n",
    "        'synopsis', 'nsfw', 'created_at', 'updated_at','recommendations'                                   # Description, MyAnimeList edits\n",
    "        \n",
    "        'main_picture_medium', 'main_picture_large',                                       # Media data\n",
    "        'alternative_titles_en', 'alternative_titles_ja', 'alternative_titles_synonyms']   # Other titles\n",
    "\n",
    "\n",
    "anime = anime[order]\n",
    "\n",
    "# Save to csv\n",
    "anime.to_csv('data/anime.csv', index=False)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "anime.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>media_type</th>\n",
       "      <th>mean</th>\n",
       "      <th>num_scoring_users</th>\n",
       "      <th>status</th>\n",
       "      <th>num_episodes</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "      <th>num_list_users</th>\n",
       "      <th>popularity</th>\n",
       "      <th>num_favorites</th>\n",
       "      <th>rank</th>\n",
       "      <th>average_episode_duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>start_season_year</th>\n",
       "      <th>start_season_season</th>\n",
       "      <th>broadcast_day_of_the_week</th>\n",
       "      <th>broadcast_start_time</th>\n",
       "      <th>genres</th>\n",
       "      <th>studios</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>main_picture_medium</th>\n",
       "      <th>main_picture_large</th>\n",
       "      <th>alternative_titles_en</th>\n",
       "      <th>alternative_titles_ja</th>\n",
       "      <th>alternative_titles_synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1866190</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>manga</td>\n",
       "      <td>2923909</td>\n",
       "      <td>3</td>\n",
       "      <td>204136</td>\n",
       "      <td>2</td>\n",
       "      <td>0 days 00:24:20</td>\n",
       "      <td>r</td>\n",
       "      <td>2009</td>\n",
       "      <td>spring</td>\n",
       "      <td>sunday</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>[Action, Adventure, Drama, Fantasy, Military, ...</td>\n",
       "      <td>[Bones]</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>white</td>\n",
       "      <td>2008-08-21 03:35:22</td>\n",
       "      <td>2022-04-18 05:06:13</td>\n",
       "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
       "      <td>https://api-cdn.myanimelist.net/images/anime/1...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>[Hagane no Renkinjutsushi: Fullmetal Alchemist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                             title media_type  mean  num_scoring_users  \\\n",
       "0  5114  Fullmetal Alchemist: Brotherhood         tv  9.13            1866190   \n",
       "\n",
       "            status  num_episodes start_date   end_date source  num_list_users  \\\n",
       "0  finished_airing            64 2009-04-05 2010-07-04  manga         2923909   \n",
       "\n",
       "   popularity  num_favorites  rank average_episode_duration rating  \\\n",
       "0           3         204136     2          0 days 00:24:20      r   \n",
       "\n",
       "   start_season_year start_season_season broadcast_day_of_the_week  \\\n",
       "0               2009              spring                    sunday   \n",
       "\n",
       "  broadcast_start_time                                             genres  \\\n",
       "0             17:00:00  [Action, Adventure, Drama, Fantasy, Military, ...   \n",
       "\n",
       "   studios                                           synopsis   nsfw  \\\n",
       "0  [Bones]  After a horrific alchemy experiment goes wrong...  white   \n",
       "\n",
       "           created_at          updated_at  \\\n",
       "0 2008-08-21 03:35:22 2022-04-18 05:06:13   \n",
       "\n",
       "                                 main_picture_medium  \\\n",
       "0  https://api-cdn.myanimelist.net/images/anime/1...   \n",
       "\n",
       "                                  main_picture_large  \\\n",
       "0  https://api-cdn.myanimelist.net/images/anime/1...   \n",
       "\n",
       "              alternative_titles_en       alternative_titles_ja  \\\n",
       "0  Fullmetal Alchemist: Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST   \n",
       "\n",
       "                         alternative_titles_synonyms  \n",
       "0  [Hagane no Renkinjutsushi: Fullmetal Alchemist...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv('data/anime.csv')\n",
    "\n",
    "columns_dtype_datetime = ['start_date', 'end_date', 'created_at', 'updated_at']\n",
    "for col in columns_dtype_datetime:\n",
    "    data[col] = pd.to_datetime(data[col])\n",
    "\n",
    "columns_dtype_Int64 = ['num_episodes', 'popularity', 'rank', 'start_season_year']\n",
    "for col in columns_dtype_Int64:\n",
    "    data[col] = data[col].astype('Int64')\n",
    "\n",
    "columns_dtype_list = ['genres', 'studios', 'alternative_titles_synonyms']\n",
    "for col in columns_dtype_list:\n",
    "    data[col] = data[col].apply(literal_eval)\n",
    "\n",
    "data['broadcast_start_time'] = pd.to_datetime(data['broadcast_start_time']).dt.time   # Time of day\n",
    "\n",
    "data['average_episode_duration'] = pd.to_timedelta(data['average_episode_duration'])  # Duration\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53b5bf601465e97d3bc26103c3f6e93ae804cb5db8486c47b1991b59c7b6e7bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
